# mapping reads to maize reference genome APGv4 official release (with all contigs):

# download and index reference genome:
I downloaded the official v4 genome release to farm and unzipped using gunzip --keep Zea_mays.B73_RefGen_v4.dna.toplevel.fa.gz
# Download record:
ftp site:  ftp://ftp.gramene.org/pub/gramene/release-59/fasta/zea_mays/dna/
file: Zea_mays.B73_RefGen_v4.dna.toplevel.fa.gz
works on farm if I use the following commands (in srun interactive at 8G, 8hrs (large file!)):
ftp -p ftp.gramene.org
cd pub/gramene/release-59/fasta/zea_mays/dna/
get README # works!
get CHECKSUMS
get Zea_mays.B73_RefGen_v4.dna.toplevel.fa.gz # only took a few minutes!
grep 'toplevel' CHECKSUMS
sum Zea_mays.B73_RefGen_v4.dna.toplevel.fa.gz # CHECKSUM match verified
(if prompted, login as anonymous with a password as your email as a courtesy)
Moved draft reference with no contigs and its indexes to new subdirectory: data/refMaize/AGPv4_no_contigs/
Now making symlink:
refMaize$ ln -s /group/jrigrp/Share/assemblies/Zea_mays_RefGen_Officialv4Release_AllChrsAndContigs/Zea_mays.B73_RefGen_v4.dna.toplevel.fa
 Zea_mays.B73_RefGen_v4.dna.toplevel.fa
And indexing for bwa, picard, and samtools
module load bio
refMaize$ samtools faidx Zea_mays.B73_RefGen_v4.dna.toplevel.fa # COMPLETED
module load picardtools # saves variable $PICARD for path to picard v.2.7.1
refMaize$ java -jar $PICARD/picard.jar CreateSequenceDictionary R=AGPv4_official.fa O=AGPv4_official.dict
# now index for BWA
scripts$ sbatch indexRefBWA.sh
Submitted batch job 7695978 - try again:
Submitted batch job 7695980 - COMPLETE


# HILO PASS1 - MARCH2018
# Re-mapping pass1 = all currently sequenced hilo individuals to the official v4 genome with all contigs: data/hilo_bam_mapped2v4_allContigs
scripts$ sbatch map2maizeAPGv4_hilo.sh
Submitted batch job 7806669 - RUNNING 12.27.18. Rerunning the 3 that timed out:
scripts$ sbatch --array=15,17,149 -x bigmem3,bigmem6 -t 6-00:00:00 map2maizeAPGv4_hilo.sh
Submitted batch job 7997990 - COMPLETE 1.4.19
# now filtering newly mapped bams
scripts$ sbatch --array=1-200 -x bigmem3,bigmem6 addReadGroupandSortBam_hilo.sh
Submitted batch job 8010922 - Cancelled:
Submitted batch job 8011221 - RAN 1.4.19 - ERROR (no space on device for samtools sort tmp) for several individuals, re-running those individuals:
scripts$ sbatch --array=27-29,34,36-38,40-46,48,50-51,60-61,63,65,72,73,76,78-79,81-83,176-177,194,197,199-200 -p med2 addReadGroupandSortBam_hilo.sh
Submitted batch job 8407394 - 2.4.19. COMPLETED 2.6.19
scripts$ sbatch --array=1-200 -x bigmem3,bigmem6 --dependency=afterok:8011221 dedupAndAddBAQ_hilo.sh
Submitted batch job 8011413 - RAN WITH ERRORS 1.4.19 (no sam for ones that didn't finish above, and no space left on disk for others. Re-running:
scripts$ sbatch --array=1-83,117-200 -p med2 dedupAndAddBAQ_hilo.sh
Submitted batch job 8453633 - stopped with OUT OF MEMORY errors 2.6.19 -- ACK! memory and input SAM issues (no header -- maybe no file -- ok only for HILO80 which doesn't exist)
ERRORS:
[bam_fillmd] input SAM does not have header. Abort!
OUT-OF-MEMORY -- this is because med2 by default only allocates 2000M memory instead of 8G. rerunning:
scripts$ sbatch --array=1-83,117-200 -p bigmemm dedupAndAddBAQ_hilo.sh
Submitted batch job 8673528 - COMPLETED 2.11.19
# made symlink to new folder and naming system
# NOTE: better to use absolute paths for target (=actual file) of symbolic links
~/hilo/filtered_bams$ for i in {1..70} {72..79} {81..200}; do ln -s /home/ecalfee/hilo/data/hilo_bam_mapped2v4_allContigs/results/hilo_$i.sort.dedup.baq.bam results/March2018/HILO$i.sort.dedup.baq.bam; done
~/hilo/filtered_bams$ for i in {1..70} {72..79} {81..200}; do ln -s /home/ecalfee/hilo/data/hilo_bam_mapped2v4_allContigs/results/hilo_$i.sort.dedup.baq.bam.bai results/March2018/HILO$i.sort.dedup.baq.bam.bai; done
# 80 has no data and oops 71 didn't actually work on remapping (empty bam). Will redo:
# first making symlinks:
data/HILO_raw_reads/March2018$ ln -s $(ls /group/jrigrp6/DanAlignments/HILO71/HILO71_*_1.fq.gz) HILO71_1.fq.gz
data/HILO_raw_reads/March2018$ ln -s $(ls /group/jrigrp6/DanAlignments/HILO71/HILO71_*_2.fq.gz) HILO71_2.fq.gz
# and files with just one ID to redo listed:
hilo/data/HILO_raw_reads$ echo March2018 > March2018_lanes.list
hilo/data/HILO_raw_reads$ echo HILO71 > March2018_IDs.list
hilo/data/HILO_raw_reads$ echo March2018 > March2018_libraries.list
# now running mapping script:
filtered_bams$ sbatch --array=0 --export=DIR_IN=../data/HILO_raw_reads/March2018,PREFIX_LIST=March2018 map_and_filter_reads.sh
Submitted batch job 9297991 - ERROR 2.29.18. Oops misspecified input directory, rerunning:
filtered_bams$ sbatch --array=0 --export=DIR_IN=../data/HILO_raw_reads,PREFIX_LIST=March2018 map_and_filter_reads.sh
Submitted batch job 9404408 - COMPLETED 3.5.19 -- HILO80 doesn't exist (ok). HILO71 is the only one with empty bam (being re-done)


# Do I have adapter contamination? Let's check..
hilo_bam_mapped2v4_allContigs$ zgrep --color 'CAAGCAGAAGACGGCATACGAGAT' /group/jrigrp6/DanAlignments/HILO2/HILO2_USPD16082576-K2561_H3HFWCCXY_L7_2.fq.gz # there's some very low level of contamination (just a few reads)

# HILO PASS2 - JANUARY 2019:
# Mapping new sequences from novogene:
# First making symlink to rename logically:
hilo$ parallel 'ln -s /group/jrigrp3/HILO/hwftp.novogene.com/C202SC18113915/raw_data/HILOpl{1}/HILOpl{1}_*_{4}.fq.gz data/HILO_raw_reads/Jan2019_{3}/{2}_{4}.fq.gz' ::: $(cut -f2 data/HILO_raw_reads/Jan2019_id_link_HILO_novogene.txt | cut -c5-) :::+ $(cut -f1 data/HILO_raw_reads/Jan2019_id_link_HILO_novogene.txt) :::+ $(cut -f2 data/HILO_raw_reads/Jan2019_id_link_HILO_novogene.txt | cut -c5) ::: 1 2
# make files that save lanes and HILO ID's
hilo/data/HILO_raw_reads$ cut -f1 Jan2019_id_link_HILO_novogene.txt > Jan2019_IDs.list
data/HILO_raw_reads$ for i in $(cut -f2 Jan2019_id_link_HILO_novogene.txt | cut -c5); do echo Jan2019_$i; done > Jan2019_lanes.list
# libraries should be the same as March2018 (just re-sequenced same libraries)
hilo/data/HILO_raw_reads$ for i in {1..114}; do echo "March2018"; done > Jan2019_libraries.list
# made new script that takes in a directory and a file prefix for _IDs.txt and _lanes.txt files, then maps, adds readgroups (library = March2018, RG ID=lane, Sample_ID = HILO_ID)
# testing script analyses/filtered_bams/map_and_filter_reads.sh using just 50 reads from 1 sample:
data/HILO_raw_reads$ zcat Jan2019_6/hilo_201_1.fq.gz | head -n 50 | gzip > TEST/Jan2019_6/hilo_201_1.fq.gz
data/HILO_raw_reads$ zcat Jan2019_6/hilo_201_2.fq.gz | head -n 50 | gzip > TEST/Jan2019_6/hilo_201_2.fq.gz
# testing:
filtered_bams$ sbatch --array=0 --export=DIR_IN=../data/HILO_raw_reads/TEST,PREFIX_LIST=Jan2019 map_and_filter_reads.sh
# running all newly sequenced novogene samples:
filtered_bams$ sbatch --array=0-113 --export=DIR_IN=../data/HILO_raw_reads,PREFIX_LIST=Jan2019 map_and_filter_reads.sh
Submitted batch job 8711515 - RAN 2.12.19. MOST COMPLETED,
# BUT SOME FAILED AT DIFF STEPS WITH ERROR slurmstepd: error: get_exit_code task 0 died by signal
grep 'CANCELLED' slurm-log/*8711515*.out | sort --version-sort
Failed jobs (n=18): 6,17,70,72,77,78,81,90,91,94,96,101,102,105,106,108,110,111
~/hilo$ for i in 6 17 70 72 77 78 81 90 91 94 96 101 102 105 106 108 110 111; do echo $i; grep 'sorting BAM' slurm-log/*8711515_$i.out; done
mapped & sorted, just needs duplicates marked: 17,70,72,91,101,102,105,108
# mapping again ones that didn't map:
filtered_bams$ sbatch --array=6,77,78,81,90,94,96,106,110,111 --export=DIR_IN=../data/HILO_raw_reads,PREFIX_LIST=Jan2019 map_and_filter_reads.sh
Submitted batch job 8754543 - RUNNING 2.12.19
# deduplicating/BAQ ones that did map but didn't finish:
filtered_bams$ sbatch --array=17,70,72,91,101,102,105,108 --export=DIR_IN=../data/HILO_raw_reads,PREFIX_LIST=Jan2019 just_filter_reads.sh
Submitted batch job 8754793 - COMPLETED 2.13.19 (note #17 had many 'large duplicate sets')
# checking all bams are good:
hilo/filtered_bams$ for i in $(awk '{print "results/"$2"/"$1".sort.dedup.baq.bam"}' ../data/HILO_raw_reads/Jan2019_all.list); do echo "$i"; samtools view "$i" | head | grep 'truncated'; done
# none appear to be truncated. BUT two are missing:
hilo/filtered_bams$ for i in $(awk '{print "results/"$2"/"$1".sort.dedup.baq.bam"}' ../data/HILO_raw_reads/Jan2019_all.list); do echo "$i"; samtools view "$i" | head | wc -l; done
# the following files do not exist:
Jan2019_8/HILO157.sort.dedup.baq.bam # job array 93
hilo/filtered_bams$ grep -n 'HILO157' ../data/HILO_raw_reads/Jan2019_IDs.list
94:HILO157
Jan2019_8/HILO199.sort.dedup.baq.bam # job array 113
error was: "slurmstepd: error: get_exit_code task 0 died by signal". I missed these two from my first attempt to restart failed jobs:
filtered_bams$ grep 'died by signal' ../slurm-log/*8711515* | sort --version-sort # see all (and compared to list above, only 3 extra: 0,93,113). I'm not sure why the bam for 0 looks okay but I'm going to rerun it anyways from mapping.
mv results/Jan2019_6/HILO201.sort.dedup.baq.bam* results/backup/. # save as backup
hilo/filtered_bams$ sbatch --array=0,93,113 -p med2 --mem=54G --export=DIR_IN=../data/HILO_raw_reads,PREFIX_LIST=Jan2019 map_and_filter_reads.sh
Submitted batch job 9457315 - COMPLETED 3.5.19


# PARVIGLUMIS - PALMAR CHICO POPULATION:
# getting large well-mixed parviglumis population to use as unadmixed sister group to allo maize
# when assessing % admixture in sympatric maize and mexicana:
# there are 50 individuals from large Palmar Chico population from Balsas River Valley
# (Li used just 4 parv. individuals from same pop in her paper)
# some are already on farm:
# ind's 25-48
# 1.7.19 downloading remaining ind's 1-24, 49-50 from iplant:
my_computer$ ssh -p 2022 ecalfee@farm.cse.ucdavis.edu
$ module load icommands
$ iinit
$ icd /iplant/home/rossibarra/PalmarChico_parents/merged_iput/merged/fastq
$ cd hilo/data/parviglumis
$ iget -K Sample_JRIAL8_21_R1.fastq.gz .
actually getting better copies from here:
/iplant/home/rossibarra/rare_alleles_seq/teosinte_50/JRIAL8/JRIAL8_fastq
and subfolders iplant4/iplant4
I used irsync to transfer to my own directory, then irsync to get them onto farm

# rename all as symlinks to PARV1_1.fq.gz, PARV1_2.fq.gz etc.
data/parviglumis/PalmarChico$ for i in {1..24} 49 50; do ln -s /home/ecalfee/hilo/data/parviglumis/teosinte_50/Sample_JRIAL8_"$i"_R1.fastq.gz PARV"$i"_1.fq.gz; done
data/parviglumis/PalmarChico$ for i in {1..24} 49 50; do ln -s /home/ecalfee/hilo/data/parviglumis/teosinte_50/Sample_JRIAL8_"$i"_R2.fastq.gz PARV"$i"_2.fq.gz; done
# and same with symlinks from the ones stored locally on farm
data/parviglumis/PalmarChico$ for i in {25..48}; do ln -s /group/jrigrp9/wbmei/PalmarChico_70samples/50sample/cleaned_fastq_JRIAL8/clean_JRIAL8_"$i"_R1.fastq.gz PARV"$i"_1.fq.gz; done
data/parviglumis/PalmarChico$ for i in {25..48}; do ln -s /group/jrigrp9/wbmei/PalmarChico_70samples/50sample/cleaned_fastq_JRIAL8/clean_JRIAL8_"$i"_R2.fastq.gz PARV"$i"_2.fq.gz; done
# make lists of IDs, libraries, and lanes (lane I don't know)
data/parviglumis$ for i in {1..50}; do echo PARV"$i"; done > PalmarChico_IDs.list
data/parviglumis$ for i in {1..50}; do echo JRIAL8-"$i"; done > PalmarChico_libraries.list
data/parviglumis$ for i in {1..50}; do echo PalmarChico; done > PalmarChico_lanes.list
# map all parviglumis 1-50 to the maize reference genome
filtered_bams$ sbatch --array=0-49 --export=DIR_IN=../data/parviglumis,PREFIX_LIST=PalmarChico map_and_filter_reads.sh
Submitted batch job 8772167 - RUNNING 2.13.19 (note that it's PARV1-PARV50 but array is indexed 0-49
# DISK SPACE ISSUES - I HAD TO CANCEL MANY JOBS:
# ID those jobs with issues
hilo$ grep 'failed: No space left on device' slurm-log/*8772167*.out | sort --version-sort
# cancel those that ran into disk write issues
for i in {1..7} {10..17} 19 21 22 {24..27} 34 36 37 40 41 43; do scancel 8772167_17 8772167_"$i"; done
# Transferring files to jrigrp3/ partition on farm: (then I can delete after transfer those not actively used locally)
data/parviglumis$ sbatch transfer.sh
# this script does ~/hilo/data/parviglumis$ rsync -av teosinte_50/ /group/jrigrp3/PalmarChicoParvilgumis/
Submitted batch job 8896058 - RUNNING 2.15.19. Error:
rsync error: received SIGINT, SIGTERM, or SIGHUP (code 20) at rsync.c(644) [sender=3.1.2]
slurmstepd: error: get_exit_code task 0 died by signal
# TRYING AGAIN:
data/parviglumis$ sbatch -p bigmemm transfer.sh
Submitted batch job 8899203 - RUNNING 2.15.19 -- Actually farm cse help ran transfer for me. BUT overwrote one file. Getting again from iplant:
module load icommands
iinit
icd /iplant/home/rossibarra/rare_alleles_seq/teosinte_50/JRIAL8/JRIAL8_fastq
/group/jrigrp3/PalmarChicoParvilgumis$ iget -K Sample_JRIAL8_8_R1.fastq.gz .
# updated symlinks from new data home at /group/jrigrp3/ :
~/hilo/data/parviglumis/PalmarChico$ for i in {1..24} {49..50}; do rm PARV"$i"_1.fq.gz; rm PARV"$i"_2.fq.gz; ln -s /group/jrigrp3/PalmarChicoParvilgumis/Sample_JRIAL8_"$i"_R1.fastq.gz PARV"$i"_1.fq.gz; ln -s /group/jrigrp3/PalmarChicoParvilgumis/Sample_JRIAL8_"$i"_R2.fastq.gz PARV"$i"_2.fq.gz; done

# RESTART ALL PARVIGLUMIS ALIGNMENT AFTER FILES TRANSFERED AND I MAKE SYMLINKS
filtered_bams$ sbatch --array=1-7,10-17,19-22,24-30,32,34-38,40-49 -p med2 --export=DIR_IN=../data/parviglumis,PREFIX_LIST=PalmarChico map_and_filter_reads.sh
Submitted batch job 9130041 - oops I wanted to specify med2 partition. scancel and rerunning:
Submitted batch job 9130075 - 2.22.19. OUT-OF-MEMORY errors on all (even though I don't see that bams are truncated.). Also 'Broken pipe' errors in logs. Rerunning:
filtered_bams$ sbatch --array=1-7,10-17,19-22,24-30,32,34-38,40-49 --mem=48G -p med2 --export=DIR_IN=../data/parviglumis,PREFIX_LIST=PalmarChico map_and_filter_reads.sh
Submitted batch job 9144213 - DONE 2.25.19 BUT jobs 20 and 49 out of memory). Looks like #49 finished properly anyways, re-doing #20 (note: job #20 is PARV21):
filtered_bams$ sbatch --array=20 --mem=56G -t 8-00:00:00 -p med2 --export=DIR_IN=../data/parviglumis,PREFIX_LIST=PalmarChico map_and_filter_reads.sh
Submitted batch job 9404412 - RUNNING 3.4.19

TRIPSACUM:
Downloading Tripsacum reads from NCBI:
scripts$ sbatch download_ncbi_tripsacum.sh
Submitted batch job 7637946 - I cancelled to not use local scratch (possibly too big of files) - rerunningP
Submitted batch job 7638025 - DID NOT WORK. I am going to split this into 2 steps: 1) download .sra with wget and 2) use fastq-dump to convert to .fq.gz file
scripts$ sbatch -x bigmem3,bigmem9 download_ncbi_tripsacum.sh
Submitted batch job 7682734 -- needed to delete .lock and .tmp files from partial downloads
Submitted batch job 7682791 - CANCELLED : contacted NCBI and they're workign on an issue on their end. Retrying 12.27.18:
Submitted batch job 7778149 - RUNNING 12.27.18 - COMPLETED - validating checksums:
module load bio3; vdb-validate SRR7758238.sra; validate SRR7758239.sra - COMPLETED & found consistent/complete. Ran in interactive srun session.
scripts$ sbatch -x bigmem3,bigmem9 --dependency=afterok:7682791 sra_to_fastq_ncbi_tripsacum.sh
Submitted batch job 7682866 -- need to use PARALLEL-fastq-dump:
scripts$ sbatch -x bigmem3,bigmem9 --dependency=afterok:7778149 sra_to_fastq_ncbi_tripsacum.sh
Submitted batch job 7782630 - Needed -s to indicate file with local .sra:
scripts$ sbatch -x bigmem3,bigmem9 sra_to_fastq_ncbi_tripsacum.sh
Submitted batch job 7796546 - RUNNING 12.27.18 - COMPLETED
# now I need to map these tripsacum reads to the maize reference genome (will take a long time):
# first sequencing lane
scripts$ sbatch -x bigmem3,bigmem9 -t 6-00:00:00 --export="ID=trip_SRR7758238,FASTQ1=tripsacum/SRR7758238_1.fastq.gz,FASTQ2=tripsacum/SRR7758238_2.fastq.gz,DIR_OUT=tripsacum,ALL" map2maizeAPGv4.sh
Submitted batch job 8008516 - RUNNING 1.4.19 - TIMEOUT - rerunning:
scripts$ sbatch -x bigmem3,bigmem9 -t 18-00:00:00 --export="ID=SRR7758238,FASTQ1=tripsacum/SRR7758238_1.fastq.gz,FASTQ2=tripsacum/SRR7758238_2.fastq.gz,DIR_OUT=tripsacum,ALL" map2maizeAPGv4.sh
Submitted batch job 8122106 - TIMEOUT - DID NOT FINISH 1.29.19

# second sequencing lane
scripts$ sbatch -x bigmem3,bigmem9 -t 6-00:00:00 --export="ID=trip_SRR7758239,FASTQ1=tripsacum/SRR7758239_1.fastq.gz,FASTQ2=tripsacum/SRR7758239_2.fastq.gz,DIR_OUT=tripsacum,ALL" map2maizeAPGv4.sh
Submitted batch job 8008527 - RUNNING 1.4.19 - TIMEOUT - rerunning :
scripts$ sbatch -x bigmem3,bigmem9 -t 17-00:00:00 --export="ID=SRR7758239,FASTQ1=tripsacum/SRR7758239_1.fastq.gz,FASTQ2=tripsacum/SRR7758239_2.fastq.gz,DIR_OUT=tripsacum,ALL" map2maizeAPGv4.sh
Submitted batch job 8122108 - RUNNING 1.11.19 - CANCELLED DUE TO TIMEOUT 1.29.19
# after mapping both sets of fastq files, I'll remove duplicates, filter for quality,
to do this make addReadGroupandSortBam.sh and dedupAndAddBAQ_hilo.sh
# THEN I can merge the files using samtools merge.
# and put the bams and fastq files in the Shared folder on farm where I keep a symlink from my directory:


# NEW PLAN FOR TRIPSACUM 2.13.19 - I DON'T NEED ALL THE READS, ~30X SHOULD BE SUFFICIENT
# The short paired-end sequences SRR7758238 have ~136.5G. That is 59x for a 2.3Gbp maize genome.
# So I will start by randomly sampling 50% of the reads

# Downsample short reads to 50% (use same random seed for _1 and _2 to get pairs):
filtered_bams$ sbatch -p med2 subsample_tripsacum_fastq.sh
Submitted batch job 8777638 - COMPLETED 2.13.19

# making all additional files to run mapping once above is finished
data/tripsacum$ echo TRIP > SRR7758238_IDs.list
data/tripsacum$ echo SRR7758238 > SRR7758238_libraries.list
data/tripsacum$ echo SRR7758238 > SRR7758238_lanes.list

# mapping on med2 with 15 days to map, 32G total memory, and 16 threads:
filtered_bams$ sbatch --dependency=afterok:8777638 -p med2 -t 15-00:00:00 --array=0 --export=DIR_IN=../data/tripsacum,PREFIX_LIST=SRR7758238 map_and_filter_reads.sh
Submitted batch job 8777664 - CANCELLED 2.13.19 - I cancelled due to memory issues.
# how I confirmed needed to be cancelled:
hilo$ grep 'failed: No space left on device' slurm-log/*8777664* # RERUNNING:
filtered_bams$ sbatch -p med2 -t 15-00:00:00 --array=0 --export=DIR_IN=../data/tripsacum,PREFIX_LIST=SRR7758238 map_and_filter_reads.sh
Submitted batch job 9130021 - 2.22.19. OUT-OF-MEMORY. Rerunning:
filtered_bams$ sbatch -p med2 -t 15-00:00:00 --array=0 --mem=64G --export=DIR_IN=../data/tripsacum,PREFIX_LIST=SRR7758238 map_and_filter_reads.sh
Submitted batch job 9143417 - COMPLETE 3.4.19

# MAIZE LANDRACES:
# LANDRACES ACROSS AMERICAS FROM LI:
# New landraces : 4 lowland mexico, 6 lowland South America & 5 Andes
# ind's listed in ~/hilo/data/landraces_fromLi/alloMaizeInclude.list
# (will check andean ind's to confirm no admixture later)

# Li used v3 but remapped to APGv4 and shared her remapped bams here: /iplant/home/lilepisorus/landraces_AGPv4
# downloading bams
ssh -p 2022 ecalfee@farm.cse.ucdavis.edu # connect to port 2022 for file downloads on farm
cd hilo/data/landraces_fromLi/original
# use icommands to get files (sign in for iplant use, -K checks checksums)
module load icommands
iinit # login w/ password
# run my script to download data from iplant with nohup in background, hopefully this works (?)
ecalfee@c11-42:~/hilo/data/landraces_fromLi/original$ nohup ../../../scripts/getLiDataiplant.sh &
[1] 18482
# did not work :/ . So first I am using irsync to get files from Li's iplant directory
# onto mine (to free up her space). Then I'll delete files I don't need (DONE) and use irsync
# again to get the files onto farm
my_computer$ irsync -r -V i:/iplant/home/lilepisorus/landraces_AGPv4 i:/iplant/home/ecalfee/landraces_fromLi
# now attempting to sync directly to farm
my_computer$ ssh -p 2022 ecalfee@farm.cse.ucdavis.edu
$ module load icommands
$ iinit
$ irsync -r -V i:/iplant/home/ecalfee/landraces_fromLi ~/hilo/data/landraces_fromLi/original
# first ran above with -s option (faster, only checks size), then ran without -s so it uses checksums

# ISSUE: RIMMA0625.bam was corrupted, so I downloaded an older uncorrupted v3 version from Li's iplant and will have to remap it to v4 myself:
/iplant/home/lilepisorus/RIMMA0625_Andean.IndelRealigned.bam
# NOTE: I moved the corrupted/truncated v4 bam to data/landraces_fromLi/original/corrupt/RIMMA0625.bam
# remapping corrupted bam:
filtered_bams$ sbatch -p med2 --export=ID=RIMMA0625,DIR_IN=../data/landraces_fromLi/original,BAM=RIMMA0625_Andean.IndelRealigned.bam bam2fastq2v4.sh
Submitted batch job 8781503 - RUNNING 2.13.19. FAILED 2.15.19 DUE TO DISK SPACE OVERLOAD.
NEED TO RERUN JUST FROM FASTQ PART
# redoing from fastq stage all the way through deduplication:
filtered_bams$ sbatch --export=ID=RIMMA0625,DIR_IN=/group/jrigrp4/landraces_v4_fromLi2017/original/fastq,LANE=alloMAIZE threefastq2v4.sh
Submitted batch job 8899475 - 2.15.19. KILLED (OUT OF MEMORY). Also problem with picard. RESTARTING (but won't have to realign paired 12 reads):
filtered_bams$ sbatch --export=ID=RIMMA0625,DIR_IN=/group/jrigrp4/landraces_v4_fromLi2017/original/fastq,LANE=alloMAIZE threefastq2v4.sh
Submitted batch job 9130024 - 2.22.19. COMPLETED.

# made ID files for allopatric maize from Li:
data/landraces_fromLi/original$ cat MexLow2.txt SA_Low2.txt Andes2.txt | cut -f1 > ../alloMAIZE_IDs.list
data/landraces_fromLi/original$ for i in {1..15}; do echo alloMAIZE; done > ../alloMAIZE_lanes.list
data/landraces_fromLi/original$ cat MexLow2.txt SA_Low2.txt Andes2.txt | cut -f1 > ../alloMAIZE_libraries.list

# DUE TO DISK SPACE, I moved Li's landrace bams to another directory on farm:
/group/jrigrp4/landraces_v4_fromLi2017$ mv ~/hilo/data/landraces_fromLi/original/ ./original/
# NEXT I'LL NEED TO RESTART REMAPPING PROCESS. OOPS file transfer interrupted. Using a script with rsync:
~/hilo/data/landraces_fromLi$ sbatch transfer.sh
script runs: rsync -av original/ /group/jrigrp4/landraces_v4_fromLi2017/original/
Submitted batch job 8896263 -- RUNNING 2.15.19. Added --checksum to command because I likely partially transferred some files with mv earlier (oops):
Submitted batch job 8896787 - RUNNING 2.15.19 (ok, well, this second attempt didn't work because source folder was removed when transferred, so it's all done, but no bams look truncated so that's good).
# made symlink for bams back to my results directory:
filtered_bams/results/alloMAIZE$ for i in $(cat ../../data/landraces_fromLi/alloMAIZE_IDs.list); \
do ln -s /group/jrigrp4/landraces_v4_fromLi2017/original/"$i".bam "$i".bam; done # made link for all but RIMMA0625.bam of course which I'll need to add later after remapping

# Run sort and read filtering on Li's landraces (#9, RIMMA0625) will have to be done later:
filtered_bams$ sbatch -p med2 --array=0-8,10-14 --export=DIR_IN=../data/landraces_fromLi,PREFIX_LIST=alloMAIZE sort_and_filter_reads.sh
Submitted batch job 8898118 - DIED 2.15.19 'slurmstepd: error: get_exit_code task 0 died by signal'. RERUNNING:
Submitted batch job 8898756 - 2.15.19 0,1 COMPLETED. SOME JOBS NEED RERUNNING (don't rerun 14 -- it's separately created):
filtered_bams$ sbatch -p med2 --array=2,3,7 --mem=40G --export=DIR_IN=../data/landraces_fromLi,PREFIX_LIST=alloMAIZE sort_and_filter_reads.sh
Submitted batch job 9130010 - 2.22.19. COMPLETED. I skipped #9 (RIMMA0399) when I shouldn't have:
filtered_bams$ sbatch -p med2 --array=9 --mem=40G --export=DIR_IN=../data/landraces_fromLi,PREFIX_LIST=alloMAIZE sort_and_filter_reads.sh
Submitted batch job 9144283 - 2.25.19 COMPLETED.

# REMAPPING Anne's 4 LOWLAND MEXICAN MAIZE POPULATIONS TOO (n=16):
# ALTERNATIVE would be to change headers (see 'reorder' script) for some of Anne's maize bams just to view on PCA
filtered_bams$ sbatch --array=1-4,11-14,21-24,31-34 --export=DIR_IN=../data/alloMaize4Low,LANE=MAIZE4LOW bam2fastq2v4_MAIZE4LOW.sh
Submitted batch job 9144329 - ERROR 2.25.19. note this is on bigmemm, so may take longer (check in). Fixed typo in bam file name. rerunning:
Submitted batch job 9144377 - IS NOT FINDING FASTQ FILES because of typo. Rerunning that part when first part finishes:
filtered_bams$ sbatch --array=1-4,11-14,21-24,31-34 --dependency=afterok:9144377 --export=DIR_IN=../data/alloMaize4Low,LANE=MAIZE4LOW,MAKEFASTQ=FALSE bam2fastq2v4_MAIZE4LOW.sh
Submitted batch job 9148795 - out of memory 2.26.19. not sure why it's exceeding memory, but I reduce sorting threads, increase default memory, and re-run:
filtered_bams$ sbatch --array=1-4,11-14,21-24,31-34 --export=DIR_IN=../data/alloMaize4Low,LANE=MAIZE4LOW,MAKEFASTQ=FALSE bam2fastq2v4_MAIZE4LOW.sh
Submitted batch job 9164203 - COMPLETED 3.4.19, BUT #3 failed (even though it says 'completed'). See grep 'failed' ../slurm-log/*9164203*.out. I can just exclude that one.
filtered_bams$ sbatch --array=3 --export=DIR_IN=../data/alloMaize4Low,LANE=MAIZE4LOW,MAKEFASTQ=FALSE bam2fastq2v4_MAIZE4LOW.sh
Submitted batch job 9456174 - FAILED 3.4.19 (no header on sam)
Error: Exception in thread "main" java.lang.OutOfMemoryError: GC overhead limit exceeded
# I think I should just exclude this one sample.

# merging sets of reads from the same sample & dedup & index again
# first make lists to merge:
data/HILO_raw_reads$ paste -d$'\t' Jan2019_IDs.list Jan2019_lanes.list Jan2019_libraries.list > Jan2019_all.list
data/HILO_raw_reads$ for i in {1..79} {81..200}; do echo HILO$i$'\t'March2018$'\t'March2018; done > March2018_all.list
data/HILO_raw_reads$ cat March2018_all.list Jan2019_all.list > merged_all.list # get full list
data/HILO_raw_reads$ mkdir ../../filtered_bams/results/to_merge
data/HILO_raw_reads$ for i in $(cut -f1 merged_all.list | sort --version-sort | uniq); do awk -v i="$i" '$1 == i {print "/home/ecalfee/hilo/filtered_bams/results/"$2"/"$1".sort.dedup.baq.bam"}' merged_all.list > ../../filtered_bams/results/to_merge/"$i".list; done
# make a script that merges as needed, or skips and just creates a symlink if no bams need to be merged
filtered_bams$ sbatch merge_bams_HILO.sh
Submitted batch job 9438264 # RAN (very fast) 3.4.19 
# redo for HILO71,157,201,199 too (filtering hadn't completed yet).
filtered_bams$ sbatch --array=71,157,201,199 merge_bams_HILO.sh
Submitted batch job 9573823 - COMPLETED 3.5.19
# oops I deleted HILO80. Will redo:
filtered_bams$ sbatch --array=80 -t 1:00:00 merge_bams_HILO.sh
Submitted batch job 9584598 - COMPLETED 3.6.19

# TO DO: run flagstat on all bams
# TO DO: make symlink to metrics for remapped hilo individuals
# TO DO: confirm with Anne correct parviglumis
