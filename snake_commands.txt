# HMMM.... BENCHMARKS:
# how can I log how a task is doing??
--cluster-status ./status.py
# see example here: https://snakemake.readthedocs.io/en/stable/tutorial/additional_features.html
a 2.4G file only took 7hrs (24304seconds) real time, and 101 hrs (364921sec) cpu time
that's using 16 threads.
Max memory was <14G

what do I expect for samtools??

# HOW DO I STOP AND RESTART SNAKEMAKE?
# Can I restart failed jobs with double time and double memory? yes, done.
# I want to log cluster-status. skip for now.
OUT_OF_MEMORY CANCELLED STOPPED TIMEOUT FAILED
PENDING RUNNING COMPLETED COMPLETING SUSPENDED
--parsable #within cluster call . skip for now.
--cluster-status ./status.py #in profile
# test with a task that should run out of memory (give way too little)
# test also with a task that should run out of time (too little time)
# and some that should run through, but take a min or two
--max-status-checks-per-second 0.2

# can memory take in file size?
snakemake -n --quiet # will just print final summary


# I CANCELLED MY SCREEN SNAKEMAKE JOB WITH THESE PROCESSES LEFT TO RUN:
21567559   bigmemm bwa_map.  ecalfee  R     8:53:03      1 16  64G    bigmem8
21567566   bigmemm bwa_map.  ecalfee  R     1:41:03      1 16  64G    bigmem3
21567565   bigmemm bwa_map.  ecalfee  R     1:52:03      1 16  64G    bigmem7
21567563   bigmemm bwa_map.  ecalfee  R     3:58:50      1 16  64G    bigmem6
21567562   bigmemm bwa_map.  ecalfee  R     6:41:59      1 16  64G    bigmem7
21567573   bigmemm bwa_map.  ecalfee  R       14:04      1 16  64G    bigmem8
21567568   bigmemm bwa_map.  ecalfee  R     1:00:06      1 16  64G    bigmem5
21567569   bigmemm bwa_map.  ecalfee  R     1:00:06      1 16  64G    bigmem4
21567570   bigmemm bwa_map.  ecalfee  R     1:00:06      1 16  64G    bigmem4
21567571   bigmemm bwa_map.  ecalfee  R     1:00:06      1 16  64G    bigmem4
21567572   bigmemm bwa_map.  ecalfee  R     1:00:06      1 16  64G    bigmem4
21567567   bigmemm bwa_map.  ecalfee  R     1:04:13      1 16  64G    bigmem8
21582116      med2 remove_d  ecalfee  R        6:37      1 3   8G     c6-89
21581372   bigmemm samtools  ecalfee  R        6:37      1 4   32G    bigmem8

# TEST WITH a & b again. TEST UPDATED SNAKECODE






# testing snakemake pipeline
# make a very small dataset with 2 fastqs:
ecalfee@c6-93:~/hilo/data/HILO_raw_reads$ zcat April2020_1/HILO312_1.fq.gz | head -n 800 | gzip > TEST/a_1.fq.gz
ecalfee@c6-93:~/hilo/data/HILO_raw_reads$ zcat April2020_1/HILO312_2.fq.gz | head -n 800 | gzip > TEST/a_2.fq.gz
ecalfee@c6-93:~/hilo/data/HILO_raw_reads$ zcat April2020_1/HILO355_1.fq.gz | head -n 800 | gzip > TEST/b_1.fq.gz
ecalfee@c6-93:~/hilo/data/HILO_raw_reads$ zcat April2020_1/HILO355_2.fq.gz | head -n 800 | gzip > TEST/b_2.fq.gz
all_files = ["TEST/a.sort.dedup.baq.bam.bai", "TEST/b.sort.dedup.baq.bam.bai"]

# useful commands for conda environments:
# to list available environments
conda info -e
# to create conda environment (only do with -p 2022)
#conda create --name hilo-env --file environment.yaml
# to update conda environment: (only do when ssh'd into -p 2022)
#conda env update --name hilo-env --file envs/environment.yaml --prune
# to list packages and versions for hilo-env
#source activate hilo-env #activate
#conda list # list packages
#conda deactivate hilo-env # de-activate



# slurm nodes vs. tasks per node vs. cpus
# cores vs. nodes vs. tasks: https://docs.ycrc.yale.edu/clusters-at-yale/job-scheduling/resource-requests/
multi-process program = multiple tasks (--ntasks)
multi-threaded program = multiple cores, 1 task (--cpus-per-task)

e.g. running samtools sort with 8 threads:
https://hcc.unl.edu/docs/applications/app_specific/bioinformatics_tools/data_manipulation_tools/samtools/running_samtools_commands/
#SBATCH --nodes=1 -N
#SBATCH --ntasks-per-node=8  -n

# running bowtie2 with 16 threads.
#SBATCH --cpus-per-task=16 -c


# GREAT RESOURCE FOR SNAKEMAKE: http://garthkong.com/snakemake-resources/
# GREAT RESOURCE ON SNAKEMAKE FOR CLUSTER: https://www.sichong.site/2020/02/25/snakemake-and-slurm-how-to-manage-workflow-with-resource-constraint-on-hpc/
How to get an email for failed jobs: --mail-type {cluster.email_type} --mail-user {cluster.email}
# HOW TO USE DICTIONARIES TO MAP 1 SAMPLE TO MULTIPLE FILES: https://www.jakevc.com/posts/2019/07/snakemake-examples/
# HOW TO USE SUBWORKFLOWS: https://lachlandeer.github.io/snakemake-econ-r-tutorial/subworkflows-divide-and-conquer.html#subworkflow-basics
# DAVIS FARM USE OF SLURM AND PROFILES: http://bluegenes.github.io/posts/
# useful for later: merging files: (caution! this isn't docs for the most up-to-date snakemake)
"Here is an example where you want to merge N files together, but if N == 1 a symlink will do." https://snakemake.readthedocs.io/en/v3.9.1/project_info/faq.html


--shadow-prefix=/scratch/<username>
--use-conda
--number of submissions to slurm at a time etc.
shadow: "minimal"
# minimal only symlinks all the input files .. so make sure they are all the rule needs to access to run!

# TO-DO: get it to run, then make a .profile for basic slurm setup, check still runs
I made a profile for slurm: mkdir -p ~/.config/snakemake/slurm
nano ~/.config/snakemake/slurm/config.yaml
jobs: 100
cluster: sbatch
use-conda: true
# TO RUN WITH THIS PROFILE:
snakemake --profile slurm
# COOL -- ADD MORE MEMORY BASED ON ATTEMPT # https://snakemake.readthedocs.io/en/stable/snakefiles/rules.html

hmm...maybe resources can only take specific values (but seems not to be the case with high_mem_mb)

# then add additional quality check rules.
fast_QC
fastq_screen
samtools file information

# mark temporary output files
# then get your list of files 2 run. show DAG. start running.



snakemake -n # dry--run. could be along list!
snakemake -n --quiet # gives just a summary if there are LOTS of files
snakemake --dag **blah blah**

# don't want to see all the file paths, just the rules?
snakemake --rulegraph | dot -Tsvg > ruleGraph.svg


module load bio3
source activate hilo-env
snakemake results/TEST/b.bam --jobs 2 --cluster-config submit.json --cluster "sbatch -p {cluster.p} --mem {cluster.mem} --cpus-per-task {cluster.cpus-per-task} --time {cluster.time} --job-name {cluster.name} -e {cluster.e} -o {cluster.o}"

# ok in bash not main node
hilo$ srun --mem 8G -p med2 -t 2:00:00 --pty bash
source activate hilo-env
snakemake results/TEST/b.sort.bam --jobs 2 --cluster-config submit.json --cluster "sbatch -p {cluster.p} --mem {cluster.mem} --cpus-per-task {cluster.cpus-per-task} --time {cluster.time} --job-name {cluster.name} -e {cluster.e} -o {cluster.o}"


# create a snakemake copy of the environment.
ssh -p 2022 ecalfee@farm.cse.ucdavis.edu
module load conda3
source activate hilo-env
hilo$ snakemake -n all --use-conda --create-envs-only
Building DAG of jobs...
Conda environment ../envs/environment.yaml will be created.
hilo$ snakemake all --use-conda --create-envs-only



# anytime you update the conda environment:
ssh -p 2022 ecalfee@farm.cse.ucdavis.edu
cd hilo
hilo$ module load conda3
hilo$ conda env update --name hilo-env --file envs/environment.yaml --prune
hilo$ source activate hilo-env
hilo$ snakemake -n all --profile slurm --conda-create-envs-only
hilo$ snakemake all --profile slurm --conda-create-envs-only
#(use -n above if you just want to see which environments will be created)
hilo$ conda deactivate
hilo$ exit  # now log out of farm and re-log in without -p 2022 to run snakemake

# to run pipeline:
 start screen.
 screen -S snake
 snakemake all --profile slurm
[detached from 21715.snake] # hmm. things didn't run b/c low priority. also accidentally put screen on an sru nso lost it after I cancelled ind stalled jobs

# check after a bit if it ran through .. any errors?
# look at multiqc reports and library in bam file. samtools View bam
# then change TEST to your prefix. Commit DAG and simplified DAG.
# update GIT.
# Look at DAG. Look at simplified DAG. Then run all.
snakemake --dag all | dot -Tsvg > dag.svg
snakemake all --profile slurm
[detached from 32676.snake_run] # it's running in screen now


# argh, can't use this to parse wildcards in my 'profile', oh well: print(*{wildcards}.values(), sep = ".")





### ok so my original memory/time estimates were really high, possibly preventing my jobs from being scheduled efficiently. I added more dynamic memory with 3 total attempts for failed jobs and less intense status checking to reduce impact to farm (once every 2 sec)
### I cancelled original running snakemake process, but only had to cancel 1 individual job (let others scheduled run until complete).
### now running pipeline again:
ecalfee@farm:~/hilo$ screen -r 32676.snake_run
[detached from 32676.snake_run] 8.20.20 11pm
# two jobs got hung up (suspended). So I cancelled them. but snakemake doesn't seem to be rescheduling them.
ecalfee@farm:~$ squeue -u ecalfee
         JOBID PARTITION     NAME     USER ST        TIME  NODES CPU MIN_ME NODELIST(REASON)
      21613385   bigmemm bwa_map.  ecalfee  S     1:55:54      1 16  24G    bigmem3
      21612650   bigmemm bwa_map.  ecalfee  S     2:34:50      1 16  24G    bigmem3
ecalfee@farm:~$ screen -ls
There is a screen on:
	32676.snake_run	(05/19/2020 10:57:41 PM)	(Detached)
1 Socket in /run/screen/S-ecalfee.
ecalfee@farm:~$ scancel 21613385 21612650
ecalfee@farm:~$ screen -r 32676.snake_run
# HILO306 and HILO317 are the ones that got hung up and need to be rerun. I will also check what would need to be rerun if I included all the older files too.

# first make combined list with all samples except those affected by label errors:
(hilo-env) ecalfee@c6-97:~/hilo/data/HILO_raw_reads$ (cut -f1 merged_all.list; cat April2020_IDs.list) > Combined_IDs.list
(hilo-env) ecalfee@c6-97:~/hilo/data/HILO_raw_reads$ (cut -f3 merged_all.list; cat April2020_libraries.list) > Combined_libraries.list
~/hilo/data/HILO_raw_reads$ (cut -f2 merged_all.list; cat April2020_lanes.list) > Combined_lanes.list

# I had to rename the picard and fastQC reports to get snake to recognize samples were added: multiqc_report.html.backup
# I need to simlink the fastqs for March2018 and simlink (or just copy over) all of the mark duplicate metrics from previous runs to the correct directory.
snakemake -n --quiet all --profile slurm
# to keep directory naming consistent for snakemake to find files, I created symlinks for all March2018 fastqs into the March2018/ directory, not just March2018_all/
# only HILO71 was previously symlinked into this directory
(hilo-env) ecalfee@c6-97:~/hilo/data/HILO_raw_reads$ parallel 'ln -s $(ls /group/jrigrp6/DanAlignments/{1}/{1}_*_{2}.fq.gz) March2018/{1}_{2}.fq.gz' :::: March2018_all_IDs.list ::: 1 2
<<gnu parallel message>>
ln: failed to create symbolic link 'March2018/HILO71_1.fq.gz': File exists
ln: failed to create symbolic link 'March2018/HILO71_2.fq.gz': File exists
parallel 'ln -s $(ls /group/jrigrp6/DanAlignments/{1}/{1}_*_{2}.fq.gz) March2018/{1}_{2}.fq.gz' :::: March2018_all_IDs.list ::: 1 2

# updated time-stamp for symbolic links to show snakemake these files are current:
(hilo-env) hilo$ parallel 'ln -s $(ls /home/ecalfee/hilo/data/hilo_bam_mapped2v4_allContigs/metrics/hilo_{1}.metrics.txt) filtered_bams/metrics/picard/March2018/HILO{1}.metrics.txt' ::: {1..70} {72..79} {81..200}
hilo$ parallel 'unlink filtered_bams/results/March2018/HILO{1}.sort.dedup.baq.bam; ln -s /home/ecalfee/hilo/data/hilo_bam_mapped2v4_allContigs/results/hilo_{1}.sort.dedup.baq.bam filtered_bams/results/March2018/HILO{1}.sort.dedup.baq.bam; ' ::: {1..70} {72..79} {81..200}
hilo$ parallel 'unlink filtered_bams/results/March2018/HILO{1}.sort.dedup.baq.bam.bai; ln -s /home/ecalfee/hilo/data/hilo_bam_mapped2v4_allContigs/results/hilo_{1}.sort.dedup.baq.bam.bai filtered_bams/results/March2018/HILO{1}.sort.dedup.baq.bam.bai; ' ::: {1..70} {72..79} {81..200}

# good! now snakemake doesn't want to remake these files anymore :)
(hilo-env) ecalfee@c6-97:~/hilo$ snakemake -n --quiet all --profile slurm
Job counts:
	count	jobs
	1	all
	2	bwa_map
	1004	fastQC
	1	multiQC_fastQC
	1	multiQC_flagstat
	1	multiQC_picard
	2	remove_duplicates
	315	samtools_flagstat
	2	samtools_index
	2	samtools_sort
	1331
# now I will stop and restart snakemake on my screen instance:
snakemake all --profile slurm
# running: [detached from 32676.snake_run]
# all ran fine except HILO1 b/c fastq_1 for that file appears to have been truncated!
hilo$ less filtered_bams/snake_logs/fastQC.ID\=HILO1\,LANE\=March2018\,READ\=1.21816*err
...
Approx 95% complete for HILO1_1.fq.gz
Failed to process file HILO1_1.fq.gz
uk.ac.babraham.FastQC.Sequence.SequenceFormatException: Ran out of data in the middle of a fastq entry.  Your file is probably truncated
ecalfee@c6-97:~/hilo$ zcat data/HILO_raw_reads/March2018/HILO1_1.fq.gz | wc -l
gzip: data/HILO_raw_reads/March2018/HILO1_1.fq.gz: unexpected end of file
24590717
(hilo-env) ecalfee@c6-97:~/hilo$ zcat data/HILO_raw_reads/March2018/HILO1_2.fq.gz | wc -l
33132348
# When iplant is back online I can check if we have a backup. Looks like truncation likely happened after mapping/deduplication etc. so all the reads may be there somewhere.
# for now I will just do a 'touch' placeholder for that fastQC file so I can finish snakemake.
hilo$ touch filtered_bams/metrics/fastQC/March2018/HILO1_1_fastqc.html
hilo$ snakemake -n --quiet all --profile slurm
Job counts:
	count	jobs
	1	all
	1	multiQC_fastQC
	2
snakemake all --profile slurm
# ran out of time. Increased max time to 2hrs. Will rerun when I fix the dedup step also here:
# in my original MarkDuplicates I didn't actually remove duplicates. I add a rule rm_duplicates using samtools flag 0x0400
# then to use that rule I rename my prior output HILO*.sort.mrkdup.baq.bam.
# note this only applies to the April2020 data. previous data had duplicates removed during MarkDuplicates (can see in flagstat):
hilo/filtered_bams/results/April2020_1$ for i in {300..395}; do mv HILO$i.sort.dedup.baq.bam HILO$i.sort.mrkdup.baq.bam; done
hilo/filtered_bams/results/April2020_1$ for i in {300..395}; do touch HILO$i.sort.mrkdup.baq.bam; done
hilo/filtered_bams/results/April2020_2$ for i in {396..488}; do mv HILO$i.sort.dedup.baq.bam HILO$i.sort.mrkdup.baq.bam; done
hilo/filtered_bams/results/April2020_2$ for i in {396..488}; do touch HILO$i.sort.mrkdup.baq.bam; done
# now running snakemake all for 'Combined' samples again on screen:
snakemake all -n --quiet --profile slurm
Job counts:
	count	jobs
	1	all
	1	multiQC_fastQC
	1	multiQC_flagstat
	189	rm_duplicates
	189	samtools_flagstat
	189	samtools_index
	570

# following up on truncated HILO1 -- Dan replaced with original file from /group/jrigrp6/DanAlignments/HILO1/*_1.fq.gz. I should now re-do mapping for HILO1.
# checking checksums for all other files that the ones I used from DanAlignments are identical to the originals
ecalfee@bigmem3:~/hilo$ for i in {1..200}; do md5sum /group/jrigrp6/DanAlignments/HILO"$i"/*.fq.gz > data/HILO_raw_reads/MD5_checksums/March2018/HILO"$i"_MD5.txt; done
# ugh..I just put this into a short script to submit to sbatch instead:
hilo$ sbatch scripts/check_md5sums.sh
Submitted batch job 21891631
# original checksums are here: /group/jrigrp6/RILAB_data/HILO/raw_data/HILO1/MD5.txt
# now I can do a file difference check: (except I only want to check the 1st column)
hilo$ for i in {1..79} {81..200}; do diff <(cut -f1 /group/jrigrp6/RILAB_data/HILO/raw_data/HILO"$i"/MD5.txt -d" ") <(cut -f1 data/HILO_raw_reads/MD5_checksums/March2018/HILO"$i"_MD5.txt -d" "); done
# great! just HILO1 had a truncated file. I will remap HILO1 which snakemake detected automatically because the fastq_1 was updated by Dan:
# I need to update my iplant backup using irsync - COMPLETED.
I also fixed samtools_flagstat rule to read the bam properly with - in the pipe, so all 190 of those are also running too for April2020 sequences.
Job counts:
	count	jobs
	1	all
	1	bwa_map
	2	fastQC
	1	mark_duplicates
	1	multiQC_fastQC
	1	multiQC_flagstat
	1	multiQC_picard
	1	rm_duplicates
	190	samtools_flagstat
	1	samtools_index
	1	samtools_sort
	201
[detached from 32676.snake_run]  5.26.20 9pm
# annoyingly TIMEOUT (CANCELLED) wasn't caught by slurm as a job failure, so it didn't try again. I will up time manually and run again:
# e.g. output files:
'filtered_bams/snake_logs/samtools_flagstat.ID=HILO428,LANE=April2020_2.21898239.err'
'filtered_bams/snake_logs/samtools_flagstat.ID=HILO428,LANE=April2020_2.21898239.out'
# so I added threads and 2 hours (now 6 hrs total) for initial samtools flagstat run -- HILO301, HILO305, HILO428:
[detached from 32676.snake_run] #May 27, 9:30am. Finished super fast (not sure what caused TIMEOUT earlier)
# rerun multiqc ignoring test bams:
hilo$ snakemake multiQC_picard multiQC_flagstat multiQC_fastQC -f -n --quiet --profile slurm
Job counts:
	count	jobs
	1	multiQC_fastQC
	1	multiQC_flagstat
	1	multiQC_picard
	3
(hilo-env) ecalfee@c6-97:~/hilo$ snakemake multiQC_picard multiQC_flagstat multiQC_fastQC -f --profile slurm

# testing trimmomatic:
hilo$ snakemake -f /home/ecalfee/hilo/data/HILO_trimmed_reads/TEST/a_1.fq.gz --profile slurm
# added TRUE . now seeing if it successfully removes adapters from the small test sets of reads:
snakemake metrics/fastQC_trimmed/multiqc/multiqc_report.html --profile slurm
# looks good on fastQC report!

# I made an alternative 'some' rule to the 'all' rule to just make trimmed_reads multiQC report and do bwa -> sorting reads. ack! in testing it removes temporary output file. So I get rid of the temp for now.
# first tested with just TEST/a.fq and b.fq. Now running with Combined sample:
hilo$ snakemake -n some --quiet --profile slurm
Job counts:
        count   jobs
        502     bwa_map
        1004    fastQC_trimmed
        1       multiQC_fastQC_trimmed
        502     samtools_sort
        1       some
        502     trimmomatic
        2512
snakemake some --profile slurm
[detached from 32676.snake_run] # May 28, 2020 11:39pm

# I will have to decide later whether I want to cap base quality scores with BAQ, so I don't dedup yet in this run:
hilo$ snakemake -n some --quiet --profile slurm
Job counts:
	count	jobs
	1	all
	502	bwa_map
	1004	fastQC_trimmed
	1	multiQC_fastQC_trimmed
	502	samtools_sort
	502	trimmomatic
	2512

# snakemake seemed frozen from log on Jun 4, so I did CTRL+C:
Terminating processes on user request, this might take some time.
Will exit after finishing currently running jobs.
Complete log: /home/ecalfee/hilo/.snakemake/log/2020-05-28T233738.667066.snakemake.log
hilo$ snakemake -n some --quiet --profile slurm
Job counts:
        count   jobs
        1       bwa_map
        4       fastQC_trimmed
        1       multiQC_fastQC_trimmed
        1       samtools_sort
        1       some
        1       trimmomatic
        9
# REMINDER, HOW TO USE SCREEN: https://linuxize.com/post/how-to-use-linux-screen/
# ok, restarting these failed jobs (can't determined why they failed from logs, so could be random)
hilo$ snakemake some --profile slurm # RUNNING 6.25.2020
CRTL+A D
[detached from 32676.snake_run]


TEST ANGSD MIXING BAMS FROM GENOMES WITH DIFF SORT ORDERS:
# take 10 maize from hilo
# and 10 maize from Palmar Chico maize pop

# are the number of SNPs reasonable? Are they all at 50% freq?
hilo/test$ angsd -out test_10JRI_10alloMAIZE -r 1:100000000-100010000 -ref ../data/refMaize/Zea_mays.B73_RefGen_v4.dna.toplevel.fa -bam maize_10JRI_10alloMAIZE.bams -remove_bads 1 -minMapQ 30 -minQ 20 -doCounts 1 -minMaf 0.05 -doMaf 8 -GL 1 -doGlf 2 -P 1 -doMajorMinor 2 -checkBamHeaders 0
hilo/test$ samtools view -bs 42.001 /home/jri/projects/ibd/JRIAL1/data/JRIAL1-2_srt_dedup.bam > small_JRIAL1-2_srt_dedup.bam
# index this bam
# try to run test2.bams -- has small_JRIAL1-2_srt_dedup.bam and some hilo's
hilo/test$ angsd -out test2 -r 2:100000000-110000000 -ref ../data/refMaize/Zea_mays.B73_RefGen_v4.dna.toplevel.fa -bam test2.bams -remove_bads 1 -minMapQ 30 -minQ 20 -doCounts 1 -minMaf 0.05 -doMaf 8 -GL 1 -doGlf 2 -P 1 -doMajorMinor 2 -checkBamHeaders 0
# again but without this 1 bam from palmar chico = test2b:
angsd -out test2b -r 2:100000000-110000000 -ref ../data/refMaize/Zea_mays.B73_RefGen_v4.dna.toplevel.fa -bam test2b.bams -remove_bads 1 -minMapQ 30 -minQ 20 -doCounts 1 -minMaf 0.05 -doMaf 8 -GL 1 -doGlf 2 -P 1 -doMajorMinor 2 -checkBamHeaders 0

# then re-sort according to the my genome
hilo/test$ samtools sort -m 6G -@ 1 -T tmp -O bam small_JRIAL1-2_srt_dedup.bam > small_JRIAL1-2_srt_dedup.resorted.bam
# and try to run test3 -- has small_JRIAL1-2_srt_dedup.resorted.bam and some hilo's
# the resulting SNP files should be the same from these two approaches if it's working
hilo/test$ angsd -out test3 -r 2:100000000-110000000 -ref ../data/refMaize/Zea_mays.B73_RefGen_v4.dna.toplevel.fa -bam test3.bams -remove_bads 1 -minMapQ 30 -minQ 20 -doCounts 1 -minMaf 0.05 -doMaf 8 -GL 1 -doGlf 2 -P 1 -doMajorMinor 2 -checkBamHeaders 1

# hmm...still headers don't match. Try picard ReorderSam:
module load java
module load picardtools/2.7.1
java -Xmx6g -jar $PICARD/picard.jar ReorderSam \
INPUT= small_JRIAL1-2_srt_dedup.bam OUTPUT=small_JRIAL1-2_srt_dedup.reordered.bam \
REFERENCE=../data/refMaize/Zea_mays.B73_RefGen_v4.dna.toplevel.fa
test4.bams has the reordered bam file:
samtools index small_JRIAL1-2_srt_dedup.reordered.bam
hilo/test$ angsd -out test4 -r 2:100000000-110000000 -ref ../data/refMaize/Zea_mays.B73_RefGen_v4.dna.toplevel.fa -bam test4.bams -remove_bads 1 -minMapQ 30 -minQ 20 -doCounts 1 -minMaf 0.05 -doMaf 8 -GL 1 -doGlf 2 -P 1 -doMajorMinor 2
# runs just fine without checking bam headers ..
# maize palmar chico needs to run ReorderSam (above) + dedup marked dups + filter to mapQ>=1
hilo/test$ samtools view -bF 0x400 -q 1 small_JRIAL1-2_srt_dedup.bam | samtools flagstat -
# ok actually I don't want to copy these all over (> 2T). As long as I just use autosomes, the order is the same in bams, so angsd should work with -checkBamHeaders flag
# BUT I do need to make sure to use the -removeBads 1 and -mapQ 30 and -baq 2 in ANGSD because these files
# have no pre-computed baq and only actually mark (not remove) duplicate reads

# make symlinks for all maize 55 data to the filtered bams folders
hilo/filtered_bams/results/Maize55$ for i in {1..55}; do ln -s /home/jri/projects/ibd/JRIAL1/data/JRIAL1-"$i"_srt_dedup.bam MAIZ"$i".sort.dedup.bam; done

# rerun snakemake to dedup all hilo and then index everything, incl. maize 55
# note that maize55 I got pre-mapped (w/ bwa) and duplicates marked, but all reads included (even unmapped)
screen -r 32676.snake_run
(IN SCREEN:)
Job counts:
	count	jobs
	1	all
	502	mark_duplicates
	1	multiQC_flagstat
	557	samtools_flagstat
	557	samtools_index
	1618
hilo$ snakemake all --profile slurm
CTRL+A+D (detached screen. June 26, 2020 11:55pm)
# ran fine. Now I merge bams for the same individual. Syntax here in snakemake is a bit tricky. shell only (not run) is required to use conda
snakemake all -n --profile slurm
# running test case with a/b files 6.30.2020. Oops next time don't test with multiQC reports (will inclue a & b test files in there too)
screen -r 32676.snake_run
[detached from 32676.snake_run]
# oops. merge bams not just for the sample cases:
(hilo-env) ecalfee@farm:~/hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        520     merge_bams
        521
(hilo-env) ecalfee@farm:~/hilo$ snakemake all --profile slurm # running 7.7.2020

# calculating depth for minQ > 20:
(hilo-env) ecalfee@farm:~/hilo$ snakemake -n calc_depth --profile slurm
Building DAG of jobs...
Job counts:
        count   jobs
        1       calc_depth
        1

[Tue Jul  7 01:46:57 2020]
rule calc_depth:
    input: ../samples/HILO_MAIZE55_bams.list, /home/ecalfee/hilo/data/refMaize/random_regions/N1000.L100.regions
    output: results/depthCov/N1000.L100.regions/HILO_MAIZE55.Q20.depthGlobal
    jobid: 0
    threads: 4
    resources: time_min=720, mem=32
# make output directory for logs!
mkdir variant_sites/snake_logs
# now run:
hilo$ snakemake calc_depth --profile slurm # didn't work. Now I've fixed the working directory issue (always just points to hilo/ for variant_sites Snakemake)
hilo$ snakemake calc_depth --profile slurm # 7.7.2020 RUNNING: Submitted job 0 with external jobid '24113628'
# now calling SNPs using a max depth cutoff that's read in from the output of the calc_depth rule
(hilo-env) ecalfee@farm:~/hilo$ snakemake -n --quiet all --profile slurm
Job counts:
        count   jobs
        1       all
        426     call_SNPs
        427
# running 7.7.2020 6pm . oops typo didn't work. trying again:
snakemake -n --quiet all  --profile slurm
Job counts:
        count   jobs
        1       all
        426     call_SNPs
        426     make_sites_file
        853

# most but not all call_SNPs completed. none of the make_sites_file rule was successful.
(hilo-env) ecalfee@farm:~/hilo$ snakemake -n --quiet all --profile slurm
Job counts:
        count   jobs
        1       all
        426     calc_rmap_pos
        116     call_SNPs
        426     make_sites_file
        969
# testing 1 file:
hilo$ snakemake variant_sites/results/HILO_MAIZE55/region_1.rpos --profile slurm
Job counts:
        count   jobs
        1       calc_rmap_pos
        1       make_sites_file
        2
# worked great. Doing 2 more files so I can also test my regions script:
hilo$ snakemake variant_sites/results/HILO_MAIZE55/region_0.rpos variant_sites/results/HILO_MAIZE55/region_300.rpos --profile slurm
# testing regions script with just 0, 1, 300 regions for now (need to change back in global_ancestry/Snakefile!!)
snakemake -n --quiet some --profile slurm
Job counts:
        count   jobs
        1       some
        1       thin_GL_4PCA
        2
No rule to produce variant_sites/results/HILO_MAIZE55/region_3.mafs.gz (if you use input functions make sure that they don't raise unexpected exceptions).
# ok thin_GL_4PCA still has issues (troubleshoot on mac). but re-running the failed jobs from call_SNPs for now:
hilo$ snakemake -n --quiet all --profile slurm --jobs 200
Job counts:
        count   jobs
        1       all
        423     calc_rmap_pos
        116     call_SNPs
        423     make_sites_file
        963
(hilo-env) ecalfee@farm:~/hilo$ snakemake all --profile slurm --jobs 200 # running 7.8.2020 all on medium priority but increased max to 200 jobs
[detached from 32676.snake_run] # ack! not sure what the deal is with farm but I won't use --jobs to override again (maybe overrides all defaults too?? like pinging the server? or could be completely unrelated)
# testing locally with a subset of regions. Need to specify --use-conda to run in updated conda environment
 Erins-MacBook-Air:hilo Erin$ snakemake test --use-conda
# can't update my conda environment on mac because of linux-ony pcangsd install :( but it runs on farm so ok

# rerunning several files because 'regions_dict' wasn't found (I think it doesn't freeze the Snakefile even when running..)
hilo$ snakemake -n --quiet all --profile slurm
Job counts:
        count   jobs
        1       all
        392     calc_rmap_pos
        1       call_SNPs
        339     make_sites_file
        1       run_NGSAdmix
        1       run_PCAngsd
        1       thin_GL_4PCA
        736
hilo$ snakemake all --profile slurm # running 7.8.2020
[detached from 32676.snake_run]

TO DO: make snakemake rules for all of the pcangsd and ngsadmix plots that you want
# NGSAdmix proportion by elevation, a PCA plot. I'll need metadata for the new maize.
# You can use the very short combined GL file as a template.

# made a file with half of the regions:
ecalfee@c6-89:~/hilo$ awk -v N=2 '(NR + 1) % N == 0' data/refMaize/divide_5Mb/ALL_regions.list > data/refMaize/divide_5Mb/HALF_regions.list
ecalfee@c6-89:~/hilo$ grep 'region_361' data/refMaize/divide_5Mb/HALF_regions.list # problem region that hasn't finished isn't included
ecalfee@c6-89:~/hilo$ head data/refMaize/divide_5Mb/HALF_regions.list
# just picked a small set of regions for a test file (downloading now from farm to laptop):
hilo Erin$ for i in 0 1 50 51 100 101 150 151 200 201 250 251 300 301 350 351 400 401; do scp -P 2022 ecalfee@farm.cse.ucdavis.edu:~/hilo/variant_sites/results/HILO_MAIZE55/region_$i.beagle.gz variant_sites/results/HILO_MAIZE55/.; done
# running test on mac for just these few regions:
(hilo-env) Erins-MacBook-Air:hilo Erin$ snakemake test
Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Unlimited resources: mem, time_min
Job counts:
	count	jobs
	1	test
	1	test_NGSAdmix
	1	test_thin_GL_4PCA
	3

# got script to run to make lists of input files by population,
# but still can't get plotting script to work for just counts (not sure why -- will check)
# now running test of getting allopatric allele frequencies (to thin sites for local ancestry)
hilo$ snakemake -n some --quiet --profile slurm
Job counts:
        count   jobs
        1       allo_freqs
        1       list_total_samples
        1       some
        3
# ok now that I fixed angsd indexing (needs .bin file too) the example in 'some' did run.
# will try running all of the regions to get MAF for allopatric references
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        851     allo_freqs
        424     index_sites_file
        1       plot_total_samples
        1277
# now running 'all'
[detached from 32676.snake_run] # Jul 19, 11:33pm
# looks like all allopatric mexicana ran overnight but there was a problem with bam file lists for allopatic maize. fixing now:
hilo$ snakemake -f list_total_samples --profile slurm
1 of 1 steps (100%) done
# now using 'touch' to avoid re-doing all allopatric mexicana (just want to re-do maize)
# and fixed small typo in plot_total_samples_pass.R (should work now)
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        426     allo_freqs
        1       plot_total_samples
        428
        # RUNNING 7.20.20 11:37am
# oops still not finding correct MAIZE55 bams. Fixed list of bams. re-did list_total_samples and 'touch' for allopatric mexicana mafs.gz files.
hilo$ snakemake -n all --quiet --profile slurm
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        426     allo_freqs
        1       plot_total_samples
        428 # RUNNING 7.20.20 12:30pm
# these jobs finished. adding PCA plots and running rule 'all' again:
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        1       plot_NGSAdmix
        1       plot_PCAngsd
        1       plot_total_samples
        1       results_NGSAdmix
        5 # runnning 7.20.20 9pm
# SWITCHED to thinning every 100th SNP for PCA/NGSAdmix instead of every .01cM (so I don't get over-representation of high recombination regions)
# moved old results to Old_0.1cM subdirectories for thinnedSNPs, PCA and NGSAdmix. Updated Snakefile to rerun.
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        1       plot_NGSAdmix
        1       plot_PCAngsd
        1       results_NGSAdmix
        1       run_NGSAdmix
        1       run_PCAngsd
        1       thin_GL_4PCA
        7 # running 7.21.20 6:25pm
# every Nth is not working in Snakefile. made it's own script and rerunnig:
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        1       plot_NGSAdmix
        1       plot_PCAngsd
        1       results_NGSAdmix
        1       run_NGSAdmix
        1       run_PCAngsd
        1       thin_GL_4PCA
        7 # running 7.21.20 12:36am
# rerunning with slight adjustments to plots:
hilo$ snakemake -n plot_PCAngsd plot_NGSAdmix --quiet --profile slurm
Job counts:
        count   jobs
        1       plot_NGSAdmix
        1       plot_PCAngsd
        2 # 7.22.20 10:15am
# added latex table output (updated conda environment for r-xtable) and re-running again:
hilo$ snakemake -n -f plot_PCAngsd plot_NGSAdmix --quiet --profile slurm
Job counts:
        count   jobs
        1       plot_NGSAdmix
        1       plot_PCAngsd
        2 # running 7.22.20 11:20am

# HMMM... the cubic spline "hyman" extrapolates out to some negative recombination map distances (!).
# I am calculating rpos based on linear approximation from the extended map, and saving old files in ls variant_sites/results/HILO_MAIZE55/splines_old/
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        426     calc_rmap_pos
        427 # running 8.3.2020 10pm. COMPLETED.

# made pipeline to do 100 bootstraps of global ancestry ~ recombination quintile (1cM window)
snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        1       define_1cM_windows
        1520    find_SNPs_in_window
        1       make_bed_file_for_windows
        505     make_bootstrap_GL_file
        1       sample_bootstrap_1cM
        2029 # running 8.4.2020 5pm. Did not work b/c it's circular to read file to get the number of 1cM windows -- have to provide that separately
        hilo$ snakemake -n all --quiet --profile slurm

Job counts:
        count   jobs
        1       all
        1       define_1cM_windows
        1520    find_SNPs_in_window
        505     label_k_anc
        1       make_bed_file_for_windows
        505     make_bootstrap_GL_file
        505     run_boostrap_NGSAdmix
        1       sample_bootstrap_1cM
        3039 # running 8.4.2020 11pm
# oops forgot double brackets in R scripts to call snakemake variables. fixed and re-trying.
# awk to find SNPs in windows still not working. added it's own bash script for awk and testing just this piece:
hilo$ snakemake ancestry_by_r/results/GL_1cM/HILO_MAIZE55/W1.beagle.gz --quiet --profile slurm
Job counts:
        count   jobs
        1       find_SNPs_in_window
        1 # finally ran through without errors. Now running all pieces:
        hilo$ snakemake all --quiet --profile slurm
        Job counts:
                count   jobs
                1       all
                1519    find_SNPs_in_window
                505     label_k_anc
                505     make_bootstrap_GL_file
                505     run_boostrap_NGSAdmix
                1       sample_bootstrap_1cM
                3036 # running 8.5.2020 10am. only ran through find_SNPs_in_window
hilo$ snakemake all --quiet --profile slurm
Job counts:
      count   jobs
      1       all
      505     label_k_anc
      505     make_bootstrap_GL_file
      505     run_boostrap_NGSAdmix
      1       sample_bootstrap_1cM
      1517 # fixed typo in path of sample_bootstrap_1cM. rerunning.

# ok problem is that the bin_r5 is not a factor with defined levels.
# so I added a column quintile_r5 that has values 1-5.
# I will force rerun define_1cM_windows and make_bed_file_for_windows
# and use touch to not have to redo find_SNPs_in_window, which would be unaffected
hilo$ snakemake -f define_1cM_windows make_bed_file_for_windows --quiet --profile slurm
Job counts:
        count   jobs
        1       define_1cM_windows
        1       make_bed_file_for_windows
        2 # COMPLETED 8.5.2020
hilo$ touch ancestry_by_r/results/GL_1cM/HILO_MAIZE55/W*.beagle.gz
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        505     label_k_anc
        505     make_bootstrap_GL_file
        505     run_boostrap_NGSAdmix
        1       sample_bootstrap_1cM
        1517 # RUNNING 8.5.2020

# NOTE: don't use any kind of shadow when running a bash script through 'shell' (or put script in as a parameter..)
# In general I don't need 'shadow' unless there's lots of reading and writing.
hilo$ snakemake -n all --quiet --profile slurm                                    Job counts:
        count   jobs
        1       all
        505     label_k_anc
        504     make_bootstrap_GL_file
        505     run_boostrap_NGSAdmix
        1515 # RUNNING 8.5.2020 6pm. hmm didn't work. debugged make_bootstrap_GL_file, label_k_anc and run_bootstrap_NGSAdmix one at a time with 1 file each

hilo$ snakemake all --quiet --profile slurm
Job counts:
      count   jobs
      1       all
      504     label_k_anc
      504     run_bootstrap_NGSAdmix
      1009 # running 8.6.2020 11am. Ran through:
# now making plots (remaking some others because I updated colors.R)
Job counts:
        count   jobs
        1       all
        1       plot_NGSAdmix
        1       plot_PCAngsd
        1       plot_bootstrap_anc_by_r
        4 # RUNNING 8.6.2020 4pm. COMPLETED ALL PLOTS
# rerunning population alphas output from ngsadmix to use as input for ancestry_hmm (admixture proportion prior)
hilo$ snakemake -f global_ancestry/results/NGSAdmix/HILO_MAIZE55/K2_alphas_by_symp_pop.txt --quiet --profile slurm
Job counts:
        count   jobs
        1       results_NGSAdmix
        1 # RUNNING 8.6.2020 5pm
hilo$ snakemake -n all --quiet --profile slurm
      Job counts:
      count   jobs
      1       all
      1       plot_NGSAdmix
      1       thin_AIMs
      3
# ERROR in thin_sites_4HMM. problem was NAs in rpos files. remaking those files:
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        426     calc_rmap_pos
        1       thin_sites_4HMM
        428 # RUNNING 8.11.2020. Again didn't work. Fixed reading in columns of extended map, deleted rpos files with lots of NAs and rerunning.
# thin sites ran. trying one file to test counts pipeline:
hilo$ snakemake local_ancestry/results/countsMajMin/HILO_MAIZE55/HILO2.counts.txt --quiet --profile slurm
Job counts:
        count   jobs
        1       count_ACGT
        1       count_maj_min
        1       index_sites_4HMM
        3 # made index of sites ok and started on ACGT counts but then I stopped the job I could run all of the samples:
hilo$ snakemake -n some --quiet --profile slurm
Job counts:
        count   jobs
        403     count_ACGT
        403     count_maj_min
        1       some
        807 # RUNNING 8.11.2020
# note the above is slightly inefficient because I have it make a counts file for all included samples (all_ids) when some sympatric samples will be excluded for coverage < 0.5x
# but rather than have dynamic inputs for each population, I can use all of these counts files as inputs for each of the following rules to make the pop input files.
farm:~/hilo$ snakemake some --quiet --profile slurm
Job counts:
        count   jobs
        49      count_ACGT
        49      count_maj_min
        1       some
        99 # some need to be rerun with higher maximum time limit (I added a thread and changed from 4 to 12 hrs because MAIZE55 bams are very large). Unfortunately, the "TIMEOUT" didn't trigger a "FAIL" and rerun.
# RUNNING 8.12.2020 9:30am


### HMM... so I want the lists of bams/IDs to be outside of my Snakemake pipeline
# so that I can use them as inputs.
# I can force rerun: rule list_total_samples in filtered_bams/Snakefile
# then use 'touch' to update downstream files (because it will be the same outputs, because results/Maize55/*.bam is symlinked to results/merged_bams/*.bam)
# then I can comment out that code and use the output files to fill a dictionary of IDs for each population
hilo$ snakemake -f list_total_samples --quiet --profile slurm
Job counts:
        count   jobs
        1       list_total_samples
        1 # RUNNING 8.13.2020 11:45am
This fixes ALLOPATRIC MAIZE LOOKS LIKE IT COMES FROM A DIFFERENT DIRECTORY IN THE ALL_byPop files! (but not Over0.5x_byPop files). this is just a symlink issue, both link to the same underlying files. But I should fix so the symlink name pattern is consistent across all bams.
# there are many downstream files that depend on list_total_samples:
        hilo$ snakemake -n all --quiet --profile slurm
        Job counts:
                count   jobs
                1       all
                852     allo_freqs
                403     count_ACGT
                403     count_maj_min
                1       index_sites_4HMM
                1       plot_total_samples
                1       thin_sites_4HMM
                1662
# touch so I don't have to remake downstream files (because will be the same since inputs changed only by name (symlink) not content)
hilo$ touch variant_sites/results/popFreq/allopatric_*/*
hilo$ touch local_ancestry/results/thinnedSNPs/HILO_MAIZE55/whole_genome.var.sites
hilo$ touch local_ancestry/results/thinnedSNPs/HILO_MAIZE55/whole_genome.*
hilo$ touch local_ancestry/results/thinnedSNPs/HILO_MAIZE55/counts_thinned_aims.txt
hilo$ touch samples/HILO_MAIZE55_byInd/*_bams.list
hilo$ touch local_ancestry/results/countsACGT/HILO_MAIZE55/*
hilo$ touch local_ancestry/results/countsMajMin/HILO_MAIZE55/*
hilo$ snakemake all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        1       plot_total_samples
        2 # DONE
# commented out list_total_samples rule and added all sample files to git!

# now trying to run ancestry_hmm with a dummy output file with the POP name (because can't have a rule define individual sample posterior outputs)
hilo$ snakemake -n local_ancestry/results/ancestry_hmm/HILO_MAIZE55/Ne10000_noBoot/pop360.completed --quiet --profile slurm
Job counts:
        count   jobs
        1       make_allo_counts
        1       make_input_hmm
        1       run_ancestry_hmm
        3 # only make_allo_counts ran. troubleshooting hmm input. need to fix spacing on allo_counts, so deleting that output and rerunning:
hilo$ snakemake local_ancestry/results/ancestry_hmm/HILO_MAIZE55/Ne10000_noBoot/pop360.completed --quiet --profile slurm
Job counts:
        count   jobs
        1       make_allo_counts
        1       make_input_hmm
        1       run_ancestry_hmm
        3 # redoing same thing -- input file not quite right (repeated maize instead of maize, then mex allele counts! and needed no scientific notation for position difference in Morgans)
# still breaks at run_ancestry_hmm. I needed to fix the dictionary to retrieve alphas. now done:
hilo$ snakemake local_ancestry/results/ancestry_hmm/HILO_MAIZE55/Ne10000_noBoot/pop360.completed --quiet --profile slurm
Job counts:
        count   jobs
        1       run_ancestry_hmm
        1

# oops ploidy file should be tab separated. rerunning:
hilo$ snakemake local_ancestry/results/ancestry_hmm/HILO_MAIZE55/Ne10000_noBoot/pop360.completed --quiet --profile slurm
Job counts:
                count   jobs
                1       make_input_hmm
                1       run_ancestry_hmm
                2 # ran but had trouble creating .completed output file . troubleshooting. Now ran.
# testing posterior to ancestry files:
hilo$ snakemake local_ancestry/results/ancestry_hmm/HILO_MAIZE55/Ne10000_noBoot/anc/pop360.anc.freq --quiet --profile slurm
Job counts:
        count   jobs
        1       summarise_posterior
        1
# running the remaining pops:
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        27      make_input_hmm
        27      run_ancestry_hmm
        27      summarise_posterior
        82 # RUNNING 8.25.2020 5pm. COMPLETED.

# hint for screen if ssh disconnects while it's still attached:
screen -rd is pretty much the standard way to attach to an existing screen session.

# now with bootstrapping:
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        28      boot_ancestry_hmm
        28      summarise_posterior
        57 RUNNING 8.25.2020 11pm
# OOPS! I identified an error in the count_maj_min.R script (was not sorting to correct order because there are many chr and positions and only sorted by pos.)
# doing 'touch' to ACGT counts (those files are ok) to re-do all downstream steps (starting with maj/min counts):
hilo$ touch local_ancestry/results/countsACGT/HILO_MAIZE55/*.counts.gz
(hilo-env) ecalfee@farm:~/hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        28      boot_ancestry_hmm
        403     count_maj_min
        1       make_allo_counts
        28      make_input_hmm
        28      run_ancestry_hmm
        56      summarise_posterior
        545 # RUNNING 8.26.2020 2pm

# only takes a few hours to re-run. make left_join with SNPs for extra security the order is correct. can now re-run:
# also added error rate for read errors 3e-3 to ancestry_hmm scripts and expanded possible time range to 0-10000 generations (10k not 1k. maize made it to the highlands ~7k ago)
hilo$ touch local_ancestry/results/countsACGT/HILO_MAIZE55/*.counts.gz
(hilo-env) ecalfee@farm:~/hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        28      boot_ancestry_hmm
        403     count_maj_min
        1       make_allo_counts
        28      make_input_hmm
        28      run_ancestry_hmm
        56      summarise_posterior
        545 # RUNNING 8.26.2020 4pm. COMPLETED.
# making tracts for ancestry calls:
hilo$ snakemake -n local_ancestry/results/thinnedSNPs/HILO_MAIZE55/whole_genome.bed --quiet --profile slurm
Job counts:
        count   jobs
        1       get_tracts_from_sites
        1 # ran but am force re-running because need to correct 0-index on bed file
        hilo$ snakemake -f local_ancestry/results/thinnedSNPs/HILO_MAIZE55/whole_genome.bed --quiet --profile slurm
        Job counts:
                count   jobs
                1       get_tracts_from_sites
                1 # DONE (very fast)

# PROBLEM: there is an issue that nInd from maf.gz is counting some individuals with reads that must be subquality (or not maj/min allele)
# so that the allo_counts are not meeting minimum # individuals to use for local ancestry calling, especially in mexicana (some zeros!)
# I moved old -doMaf 8 data to variant_sites/results/popFreq/allopatric_mexicana_doMaf8
# and modified rule allo_freqs in Snakefile/variant_sites
# I'm testing if the same problem persists with -doMaf 1 which relies on a HW assumption but should be find for allopatric pops
hilo$ snakemake -f variant_sites/results/popFreq/allopatric_mexicana/region_0.mafs.gz variant_sites/results/popFreq/allopatric_mexicana/region_1.mafs.gz variant_sites/results/popFreq/allopatric_mexicana/region_300.mafs.gz --quiet --profile slurm
Job counts:
        count   jobs
        3       allo_freqs
        3 # RUNNING FOR JUST A FEW REGIONS FIRST. CAN THEN COMPARE nIND with the tot_mex in ACGT counts for overlapping SNPs
# ADDED -GL 1 and TRYING AGAIN (SAME JOBS). worked. also tested and this gets the right nIND for allopatric counts -- great!
# I moved allo_freqs rule to local_ancestry/Snakefile
# and am rerunning all regions now with gl 1 method.
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        852     allo_freqs
        28      boot_ancestry_hmm
        403     count_ACGT
        403     count_maj_min
        1       get_tracts_from_sites
        1       index_sites_4HMM
        1       make_allo_counts
        28      make_input_hmm
        28      run_ancestry_hmm
        56      summarise_posterior
        1       thin_sites_4HMM
        1803 # RUNNING 8.31.2020. oops need to update output file prefix parameter in rule allo_freqs. rerunning:
        hilo$ snakemake -n all --quiet --profile slurm
      Job counts:
              count   jobs
              1       all
              852     allo_freqs
              28      boot_ancestry_hmm
              403     count_ACGT
              403     count_maj_min
              1       get_tracts_from_sites
              1       index_sites_4HMM
              1       make_allo_counts
              28      make_input_hmm
              28      run_ancestry_hmm
              56      summarise_posterior
              1       thin_sites_4HMM
              1803 # RUNNING 8.31.2020 12:18pm
failed to open:
filtered_bams/merged_bams/MAIZE1.sort.dedup.bam.
oops it's because all_bams is looking for the other end of this symlink: filtered_bams/MAIZE55/MAIZE1.sort.dedup.bam
(LATER I can make a symlink rule for allopatric maize instead of 'merge' for these bams.)
for now I'll just directly specify input bams. and later I can check all places all_bams is used.
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        830     allo_freqs
        28      boot_ancestry_hmm
        403     count_ACGT
        403     count_maj_min
        1       get_tracts_from_sites
        1       index_sites_4HMM
        1       make_allo_counts
        28      make_input_hmm
        28      run_ancestry_hmm
        56      summarise_posterior
        1       thin_sites_4HMM
        1781 # RUNNING 8.31.2020 (note a few allo freqs for mexicana had finished already..only maize had the path errors)
        # check on output files from ancestry_hmm -- did it run? NOT COMPLETELY:
        # some allo_freqs (66) need to be re-run. won't restart on their own if out of time (only if out of memory ..)
                # so I added resources to allo_freqs rule. and will restart.
                # First I test other new rules: make_coding_bedfile:
        hilo$ snakemake make_coding_bedfile --quiet --profile slurm
                Job counts:
                        count   jobs
                        1       make_coding_bedfile
                        1 # didn't run. fixing error and retry:
                        hilo$ snakemake make_coding_bed --quiet --profile slurm
                Job counts:
                        count   jobs
                        1       make_coding_bed
                        1 # Yikes! Can't use 'head' in bash strict mode -- it sends a 141 error down the pipe (who knew?)
                        hilo$ snakemake -p make_coding_bed --profile slurm
                        Building DAG of jobs...
                        Using shell: /bin/bash
                        Provided cluster nodes: 100
                        Job counts:
                                count   jobs
                                1       make_coding_bed
                                1

                        [Tue Sep  1 16:52:20 2020]
                        rule make_coding_bed:
                            input: /home/ecalfee/hilo/data/refMaize/geneAnnotations/Zea_mays.B73_RefGen_v4.41.chr.gff3, /home/ecalfee/hilo/data/refMaize/Zea_mays.AFPv4.dna.chr.autosome.lengths
                            output: data/refMaize/geneAnnotations/Zea_mays.B73_RefGen_v4.41.chr.CDS.bed
                            jobid: 0
                            resources: time_min=5, mem=4


                                grep -v '^#' /home/ecalfee/hilo/data/refMaize/geneAnnotations/Zea_mays.B73_RefGen_v4.41.chr.gff3 | awk -v OFS='\t' '{print $1,$4,$5,$3}' |\
                                grep 'CDS' | grep -v '^Mt' | grep -v '^Pt' |\
                                bedtools sort -faidx /home/ecalfee/hilo/data/refMaize/Zea_mays.AFPv4.dna.chr.autosome.lengths -i stdin |\
                                bedtools merge -i stdin -c 4 -o distinct > data/refMaize/geneAnnotations/Zea_mays.B73_RefGen_v4.41.chr.CDS.bed
                        # now completed make_coding_bed
hilo$ snakemake -f define_1cM_windows --quiet --profile slurm
    Job counts:
    count   jobs
    1       define_1cM_windows
    1 # COMPlETED. Now I'll rerun rule 'all' for the whole pipeline 9.1.2020.
    hilo$ snakemake all --quiet --profile slurm
    Job counts:
            count   jobs
            1       all
            66      allo_freqs
            28      boot_ancestry_hmm
            403     count_ACGT
            403     count_maj_min
            1520    find_SNPs_in_window
            1       get_tracts_from_sites
            1       index_sites_4HMM
            1010    label_k_anc
            1       make_allo_counts
            1       make_bed_file_for_windows
            1010    make_bootstrap_GL_file
            28      make_input_hmm
            1       plot_bootstrap_anc_by_r
            28      run_ancestry_hmm
            1010    run_bootstrap_NGSAdmix
            2       sample_bootstrap_1cM
            56      summarise_posterior
            1       thin_sites_4HMM
            5571 # RUNNING 9.2.2020 6pm
# because switched to -GL 1 needed to switch from 'phat' to 'knownEM' in thin_sites_4HMM
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        28      boot_ancestry_hmm
        403     count_ACGT
        403     count_maj_min
        1       get_tracts_from_sites
        1       index_sites_4HMM
        1       make_allo_counts
        28      make_input_hmm
        28      run_ancestry_hmm
        56      summarise_posterior
        1       thin_sites_4HMM
        951 # RUNNING 10:45am 9.2.2020. Fixed directory typo for alloFreqs in thin_sites_4HMM:
# just retrying thin_sties_4HMM and summaries of bootstrap data
hilo$ snakemake -n thin_sites_4HMM ancestry_by_r/results/bootstrap_1cM/HILO_MAIZE55/cd5_K2.Rdata ancestry_by_r/results/bootstrap_1cM/HILO_MAIZE55/r5_K2.Rdata --quiet --profile slurm
Job counts:
        count   jobs
        2       summarise_bootstrap_anc_by_r
        1       thin_sites_4HMM
        3 # RUNNING 2pm 9.2.2020. had typo in summarise_bootstrap. trying again:
hilo$ snakemake all --quiet --profile slurm                                                                                                   Job counts:
    count   jobs
    1       all
    28      boot_ancestry_hmm
    403     count_ACGT
    403     count_maj_min
    1       get_tracts_from_sites
    1       index_sites_4HMM
    1       make_allo_counts
    28      make_input_hmm
    28      run_ancestry_hmm
    2       summarise_bootstrap_anc_by_r
    56      summarise_posterior
    952 # RUNNING 9.2.2020. ancestry_hmm still failed ^^
# so making a 'test_ancestry_hmm' rule and using old pass2_alloMAIZE input files just to check if it's my script.
hilo$ mkdir -p local_ancestry/results/ancestry_hmm/TEST/input
hilo$ cp local_ancestry/results/ancestry_hmm/pass2_alloMAIZE/input/pop18.anc_hmm.input local_ancestry/results/ancestry_hmm/TEST/input/pop18.counts
hilo$ cp local_ancestry/results/ancestry_hmm/pass2_alloMAIZE/input/pop18.anc_hmm.ids.ploidy local_ancestry/results/ancestry_hmm/TEST/input/pop18.ploidy
hilo$ snakemake -n local_ancestry/results/ancestry_hmm/TEST/Ne10000_noBoot/pop18.completed --quiet --profile slurm
# hmm.. it ran just fine on the old files, no Nan's:
==> local_ancestry/results/ancestry_hmm/TEST/Ne10000_noBoot/posterior/HILO97.posterior <==
chrom	position	2,0	1,1	0,2
1	1961	0.159978	0.330604	0.509418
1	18830	0.191147	0.398637	0.410216
1	20171	0.187717	0.401802	0.410482
1	26286	0.173269	0.415068	0.411663
1	27214	0.301335	0.440951	0.257714
1	28687	0.163653	0.418246	0.418101
1	30261	0.155803	0.419309	0.424888
1	49527	0.0426273	0.354082	0.603291
1	51732	0.107311	0.467275	0.425414
# As compared to the new SNPs/files:
ecalfee@bigmem6:~/hilo$ head local_ancestry/results/ancestry_hmm/HILO_MAIZE55/Ne10000_noBoot/posterior/HILO97.posterior
chrom	position	2,0	1,1	0,2
1	15329	-nan	-nan	-nan
1	15841	-nan	-nan	-nan
1	18171	-nan	-nan	-nan
1	21860	-nan	-nan	-nan
1	22884	-nan	-nan	-nan
1	26555	-nan	-nan	-nan
1	27127	-nan	-nan	-nan
1	29829	-nan	-nan	-nan
1	30875	-nan	-nan	-nan

# So I'll look more closely at the input files,
e.g. TEST/input/pop18.counts and TEST/input/pop18.ploidy
vs. HILO_MAIZE55/input/pop18.counts and HILO_MAIZE55/input/pop18.ploidy
# ok so in the new dataset I manually set all non-starting rdiff that were == 1 to .00001 and will retry ancestry_hmm:
# these new files are in TEST2/input/ and I'll modify test_ancestry_hmm to run them for pop18
hilo$ snakemake local_ancestry/results/ancestry_hmm/TEST2/Ne10000_noBoot/pop18.completed --quiet --profile slurm
Job counts:
        count   jobs
        1       test_ancestry_hmm
        1 # RUNNING 9.3.2020 10am. TEST2 worked! can delete test rule now test_ancestry_hmm
# I fixed the error in thin_sites_4HMM that was setting the start of every region (not chr) to 1. And I'm rerunning from there:
hilo$ snakemake -n -f thin_sites_4HMM --quiet --profile slurm
Job counts:
        count   jobs
        1       thin_sites_4HMM
        1 # COMPLETED 10:30am. Now I'll rerun the rest. And add the new fig ouputs for ancestry_by_r too
hilo$ snakemake -f all --quiet --profile slurm
Job counts:
    count   jobs
    1       all
    28      boot_ancestry_hmm
    403     count_ACGT
    403     count_maj_min
    1       get_tracts_from_sites
    1       index_sites_4HMM
    1       make_allo_counts
    28      make_input_hmm
    1       plot_bootstrap_anc_by_r
    28      run_ancestry_hmm
    56      summarise_posterior
    951 # 9.3.2020 11:30am OOPS! ACCIDENTALLY RAN -F INSTEAD OF -N !!!
    # BUT all ok because I don't have a bunch of intermediate files (only final files)
    # in my ALL rule...so it's doing basically the same as snakemake -n all.
    # SOME ERROR IN plot_bootstrap_anc_by_r .. it was @params instead of @input for windows. Will rerun.
    # Also, a few count_ACGT and count_maj_min didn't finish properly .. will check on this
    hilo$ snakemake -n all --quiet --profile slurm
Job counts:
    count   jobs
    1       all
    28      boot_ancestry_hmm
    11      count_ACGT
    20      count_maj_min
    1       make_allo_counts
    28      make_input_hmm
    1       plot_bootstrap_anc_by_r
    28      run_ancestry_hmm
    56      summarise_posterior
    174 # RUNNING 9.4.2020 . Didn't all finish running.

# upped the time limit again becasue 24 hours wasn't enough for some of hte ACGT counts (not sure what' going $
hilo$ snakemake all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        28      boot_ancestry_hmm
        6       count_ACGT
        10      count_maj_min
        1       make_allo_counts
        28      make_input_hmm
        1       plot_bootstrap_anc_by_r
        28      run_ancestry_hmm
        56      summarise_posterior
        159 # RUNNING 9.5.2020. Many jobs still ran out of time despite high limits. problem is slurm nodes, not job time limits. reducing time and rerunning:
        hilo$ snakemake -n all --quiet --profile slurm
        Job counts:
                count   jobs
                1       all
                28      boot_ancestry_hmm
                3       count_ACGT
                8       count_maj_min
                1       make_allo_counts
                28      make_input_hmm
                1       plot_bootstrap_anc_by_r
                28      run_ancestry_hmm
                56      summarise_posterior
                154 # RUNNING 9.8.2020 1:30pm (should finish before 5am)

# UGH HILO42 counts got stalled but I want to look at prelim results.
ecalfee@bigmem3:~/hilo$ squeue -u ecalfee
         JOBID PARTITION     NAME     USER ST        TIME  NODES CPU MIN_ME NODELIST(REASON)
      25821166      med2 count_AC  ecalfee  S    10:12:14      1 2   8G     c6-89
# SO, FOR THAT FILE ONLY, I'LL USE THE OLDER DATA AND THEN REPLACE LATER:
hilo$ ls -l local_ancestry/results/countsACGT/HILO_MAIZE55/HILO42.*
-rw-rw-r-- 1 ecalfee ecalfee  493268 Sep  3 12:05 local_ancestry/results/countsACGT/HILO_MAIZE55/HILO42.counts.gz
-rw-rw-r-- 1 ecalfee ecalfee 1623390 Sep  3 12:05 local_ancestry/results/countsACGT/HILO_MAIZE55/HILO42.pos.gz
hilo$ mkdir -p local_ancestry/results/countsACGT/BACKUP_OLD
hilo$ ls -l local_ancestry/results/countsMajMin/HILO_MAIZE55/HILO42.*
-rw-rw-r-- 1 ecalfee ecalfee 1895159 Sep  3 18:49 local_ancestry/results/countsMajMin/HILO_MAIZE55/HILO42.counts.txt
hilo$ cp local_ancestry/results/countsMajMin/HILO_MAIZE55/HILO42.counts.txt local_ancestry/results/countsMajMin/BACKUP_OLD/.
hilo$ touch local_ancestry/results/countsMajMin/HILO_MAIZE55/HILO42.counts.txt
ecalfee@bigmem3:~/hilo$ date
Wed Sep  9 06:30:01 PDT 2020 # SO WHEN THE NEW FILE FINALLY RUNS IT WILL HAVE A MORE RECENT TIME STAMP AND
# I'LL HAVE TO FORCE RERUN MAJMIN AND THAT POP'S ANCESTRY_HMM (sympatric maize POP370)
# Now I CTRL+C cancel running snakemake (that one job will still con't running).
hilo$ snakemake plot_bootstrap_anc_by_r --quiet --profile slurm
Job counts:
        count   jobs
        1       plot_bootstrap_anc_by_r
        1 # COMPLETED.
        hilo$ ls -lt snake_logs/plot_boot*.out | head -n 1
        -rw-rw-r-- 1 ecalfee ecalfee 1051 Sep  9 06:42 snake_logs/plot_bootstrap_anc_by_r..25826671.out
        # this output file contains:
        [1] "Genomic feature correlation at 1cM window scale:"
        [1] "cM_Mb ~ frac_bp_coding"
        [1] 0.06325552
        [1] "quintile_r5 ~ quintile_frac5"
        [1] 0.487383
        [1] "log10(cM_Mb) ~ frac_bp_coding"
        [1] 0.4614461
        [1] "log10(cM_Mb_ ~ coding_bp"
        [1] -0.7767665
        [1] "quintile_r5 ~ quintile_cd5"
        [1] -0.8464101
# NOW TEMPORARILY COMMENTED OUT ancestry_by_r/Snakefile from snakefile imports so it builds DAG faster.
# checking which jobs need to be completed:
hilo$ snakemake -n all --profile slurm | less
hilo$ touch local_ancestry/results/countsACGT/HILO_MAIZE55/HILO42.* samples/HILO_MAIZE55_byInd/MAIZE42_bams.list
# wait several minutes
ecalfee@bigmem3:~/hilo$ touch local_ancestry/results/countsMajMin/HILO_MAIZE55/HILO42.counts.txt
# STILL, AFTER 'TOUCH' snake still wants to re-run HILO42 ACGT and MajMin counts.. I'm not sure why
# to get around this for today, I made a temporary array of IDs that doesn't include HILO42:
TEMP_ALL_IDS_EXCEPT_HILO42 = [x for i,x in enumerate(all_ids) if x!="HILO42"]
hilo$ ls -lt snake_logs/count_ACGT* | head -n 1
# see tail, it's on chr10 (good!)

# rerunning the other counts_maj_min jobs that failed:
hilo$ snakemake -n local_ancestry/results/countsMajMin/HILO_MAIZE55/HILO359.counts.txt local_ancestry/results/countsMajMin/HILO_MAIZE55/HILO416.counts.txt --quiet --profile slurm
Job counts:
        count   jobs
        2       count_maj_min
        2 # RUNNING 9.9.2020 8am
# HILO42 finally completed countsACGT. Now running the rest of the pipeline:
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        28      boot_ancestry_hmm
        2       combine_pop_ancestry_data
        1       count_maj_min
        1       make_allo_counts
        28      make_input_hmm
        28      run_ancestry_hmm
        56      summarise_posterior
        145 # RUNNING 9.9.10am
# was running but the bootstraps were slowing everything down. Putting them on bigmemm so they don't compete for resources.
hilo$ snakemake all --quiet --profile slurm
hilo$ snakemake all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        28      boot_ancestry_hmm
        2       combine_pop_ancestry_data
        26      run_ancestry_hmm
        56      summarise_posterior
        113 # RUNNING 9.9.2020 10:30am. STILL RUNNING bootstrap but others are working. adding things to 'some' rule.
        hilo$ snakemake -n some --profile slurm --quiet
        Job counts:
                count   jobs
                2       combine_pop_ancestry_data
                1       some
                3 # DIDN'T WORK, DIRECTORY 'LOCKED'. MUST WAIT FOR OTHER JOBS TO FINISH. 9.9.2020 11am
bedtools intersect -b wind.bed -a anc.bed | bedtools map -a stdin -b wind.bed -c 4 -o distinct
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        2       combine_pop_ancestry_data
        28      map_local_anc_onto_1cM_windows
        31 # SOME FAILED. Added bedtools sort to my pipeline for mapping ancestry onto windows.
        hilo$ snakemake all --quiet --profile slurm

# trying to run again summary by 1cM
Job counts:
                count   jobs
                1       all
                1       plot_bootstrap_anc_by_r
                28      summarise_local_anc_by_1cM
                30 # RUNNING 9.9.2020 2:45pm
hilo$ snakemake plot_bootstrap_anc_by_r --quiet --profile slurm
# getting timing of admixture:
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        28      get_admix_times
        1       plot_bootstrap_anc_by_r
        30 # RUNNING 9.15.2020 12:30pm. Why did plot bootstrap fail? not clear. but get_admix_times ran ok.
        (hilo-env) ecalfee@farm:~/hilo$ snakemake all --quiet --profile slurm
        Job counts:
                count   jobs
                1       all
                28      boot_ancestry_hmm
                2       combine_pop_ancestry_data
                28      get_admix_times
                28      map_local_anc_onto_1cM_windows
                2       plot_admix_times
                1       plot_bootstrap_anc_by_r
                28      summarise_local_anc_by_1cM
                28      summarise_posterior
                146 # running with 100,000 as Ne. Ran through complete.
Wanted to re-do combining ancestry freqs so it saves the mean across individuals in the .RData file as well:
So I force a rerun:
farm:~/hilo$ snakemake -f local_ancestry/results/ancestry_hmm/HILO_MAIZE55/Ne10000_yesBoot/anc/mexicana.combined.anc.bed local_ancestry/results/ancestry_hmm/HILO_MAIZE55/Ne10000_yesBoot/anc/maize.combined.anc.bed local_ancestry/results/ancestry_hmm/HILO_MAIZE55/Ne100000_yesBoot/anc/maize.combined.anc.bed local_ancestry/results/ancestry_hmm/HILO_MAIZE55/Ne100000_yesBoot/anc/mexicana.combined.anc.bed --quiet --profile slurm
Job counts:
        count   jobs
        4       combine_pop_ancestry_data
        4 # RUNNING 9.16.2020
# then uncomment ancestry_by_r, add ZAnc/Snakefile, and run 'all' rule.
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        2       calc_K_matrix_zea
        2       plot_admix_times
        2       simulate_MVN
        7 # RUNNING. simulate_MVN ran out of time but should be very fast. trying again with low time threshold .. probably computer problem.
# commented out local_ancestry and ancestry_by_r (b/c those rules all completed)
farm:~/hilo$ snakemake all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        2       calc_K_matrix_zea
        2       fit_lm_elev
        2       simulate_MVN
        7 # RUNNING 9.17.2020 on high2. (small # jobs. but I'll change the script back to med2 for safety)
        hilo$ snakemake all --quiet --profile slurm
        Job counts:
                count   jobs
                1       all
                2       fit_lm_elev
                2       simulate_MVN
                5 # FIXED SOME TYPOS. NOW RUNNING. SIMULATION FINISHED BUT STILL GOING ON MODEL FITS
                hilo$ snakemake all --quiet --profile slurm
                Job counts:
                        count   jobs
                        1       all
                        2       fit_lm_elev
                        3 # got rid of log file -- messed things up. rerunning now on high2.
# adding Ne=1k as option (note: uncommented several subsnake files before running. builds DAG slowly)
include: "local_ancestry/Snakefile"
include: "ancestry_by_r/Snakefile"
include: "ZAnc/Snakefile"
hilo$ snakemake -n all --quiet --profile slurm

# I want to re-do the MVN simulations with 10^6 instead of 10^5 sims
# so that the ratios for shared outliers are more stable:
hilo$ snakemake -n -f ZAnc/results/HILO_MAIZE55/Ne10000_yesBoot/mexicana.MVN.RData ZAnc/results/HILO_MAIZE55/Ne10000_yesBoot/maize.MVN.RData --quiet --profile slurm
Job counts:
        count   jobs
        2       simulate_MVN
        2 # RUNNING 12pm 9.29.2020
hilo$ snakemake -n all --quiet --profile slurm # TO RUN
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        2       fit_lm_elev
        2       fit_zAnc
        2       plot_mean_anc
        2       plot_shared_peaks
        2       plot_slope_elev
        11 # RUNNING 10.12.2020. uses 100k MVN simulations to get FDR thresholds for lm and zAnc outlier methods
# Oops fit_zAnc was too slow (large number of sims). I increased memory and time and made FDR calculations less time burdensome to rerun:
# outlier peaks also ran out of memory, so I increased that too. Rerunning what failed (and extra things that depend on FDR script):
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        2       fit_lm_elev
        2       fit_zAnc
        2       plot_mean_anc
        2       plot_shared_peaks
        2       plot_slope_elev
        11 # running 10.13.2020. fit_zAnc did not run through. I split into 2 scripts -- one to do fits and one to calc FDR:
# I'm also finding homozygous ancestry tracts in this run & fixed an error in file output names for plot_shared_peaks that should run now:
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        2       fdr_zAnc
        2       fit_zAnc
        56      get_homozygous_ancestry_bams
        56      get_homozygous_ancestry_tracts
        2       plot_shared_peaks
        119 # RUNNING 10.13.2020
# most rules ran through but I still had to fix one type in fdr_zAnc and scaling in plot_shared_peaks. now rerunning:
Job counts:
        count   jobs
        1       all
        2       fdr_zAnc
        2       plot_shared_peaks
        5 # RUNNING 10.13.2020. re-running fdr_zAnc -- just needed fdr functions file as input
        hilo$ snakemake -n all --quiet --profile slurm
        Job counts:
                count   jobs
                1       all
                2       fdr_zAnc
                3 # RUNNING 10.15.2020
# fixed one more typo on fdr_zAnc. Also TRACTS script did not work: filter bams to reads with high confidence homozygous ancestry (keeps whole genome)
# so I fixed that typo too but have to delete tracts output to rerun that rule.
hilo$ rm -r local_ancestry/results/ancestry_hmm/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        2       fdr_zAnc
        56      get_homozygous_ancestry_bams
        56      get_homozygous_ancestry_tracts
        115 # RUNNING 10.15.2020
# attempting to run f4 stats. first testing with rule 'some':
hilo$ snakemake -n "ancestry_by_r/results/f4/pop360.size" --quiet --profile slurm
Job counts:
        count   jobs
        1       input_abba_baba
        1 # RAN 10.22.2020
        hilo$ snakemake -n some --quiet --profile slurm
        Job counts:
                count   jobs
                1       do_abba_baba
                1       some
                2 # fixed some errors on farm, now running this 1 test 10.22.2020 4:50pm
                # oops used -rf when I mean -r and forgot -doAbbaBaba2. trying again:
                # completed.
hilo$ snakemake all --quiet --profile slurm
    Job counts:
      count   jobs
      1       all
      44079   do_abba_baba
      28      input_abba_baba
      2       plot_mean_anc
      2       plot_slope_elev
      44112. Moved to low2 for so many jobs & now running. 10.23.2020
# cancelled because many jobs timing out at 20 min. Upped to 60 min.
# also testing if it's because I'm trying to read the same files at once..
# so I'm testing just 1 file that timed-out last time:
hilo$ snakemake ancestry_by_r/results/f4/pop360/W1330.abbababa2 --quiet --profile slurm
Job counts:
        count   jobs
        1       do_abba_baba
        1 # 10.23.2020 7:30pm. Finished in only 7min.
# now running rule all (takes a long time to make DAG -- giving it 30 min)
8:45pm 10.23.2020. ugh. some kind of python error probably because of output files from half-completed jobs.
# I delete those files from pop360 and it can make a DAG again.
# I add shadow "minimal" so this hopefully doesn't happen again and the directory stays clean
# also made rule 'some' with just the sympatric maize + allopatric_maize group.
# so I can try to just run those over the weekend now instead of all of the jobs. saving symp. mexicana for later.
# testing w/ 1 file:
hilo$ snakemake ancestry_by_r/results/f4/pop360/W1.abbababa2 --quiet --profile slurm
Job counts:
        count   jobs
        1       do_abba_baba
        1 # ran in < 1 min
# now running all maize f4's:
hilo$ snakemake some --quiet --profile slurm
Job counts:
        count   jobs
        22799   do_abba_baba
        13      input_abba_baba
        1       some
        22813 # RUNNING 10.23.2020 10:.
I cancelled part way through afte 3 days of running: allopatric_maize abba baba's failed to run.
because the bams were listing just the simlink in the ALL_byPop/allopatric_maize_bams.list file, e.g. fitlered_bams/merged_bams/MAIZE1.sort.dedup.bam
but input files didn't include symlink, just original bam in filtered_bams/results/MAIZE55/MAIZE1.sort.dedup.bam
# cancelled a few pending/stalled jobs, but otherwise let running ones finish:
hilo$ scancel 26629104 26629107
So I changed how ALL_byPop/allopatric_maize bams were listed. And did 'touch' to not repeat local ancestry results.
# files I updated just using touch b/c of this change:
hilo$ touch local_ancestry/results/alloFreqs/HILO_MAIZE55/allopatric_maize/region_*
hilo$ touch local_ancestry/results/thinnedSNPs/HILO_MAIZE55/whole_genome.var.sites local_ancestry/results/thinnedSNPs/HILO_MAIZE55/whole_genome.rdiff local_ancestry/results/thinnedSNPs/HILO_MAIZE55/whole_genome.rpos local_ancestry/results/thinnedSNPs/HILO_MAIZE55/counts_thinned_aims.txt
hilo$ touch local_ancestry/results/thinnedSNPs/HILO_MAIZE55/whole_genome.bed
hilo$ touch local_ancestry/results/thinnedSNPs/HILO_MAIZE55/whole_genome.var.sites.*
# okay actual 'touch' didn't work on countsACGT, but I'll use snakemake's built in --touch for pipelines:
# first tried on just 1 file & works:
hilo$ snakemake --touch local_ancestry/results/countsACGT/HILO_MAIZE55/MAIZE1.counts.gz --profile slurm
# now running on whole pipeline:
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        84      boot_ancestry_hmm
        2       calc_K_matrix_zea
        6       combine_pop_ancestry_data
        402     count_ACGT
        403     count_maj_min
        2       fdr_zAnc
        2       fit_lm_elev
        2       fit_zAnc
        84      get_admix_times
        56      get_homozygous_ancestry_bams
        56      get_homozygous_ancestry_tracts
        28      get_maximum_a_posterior
        1       make_allo_counts
        28      make_input_hmm
        84      map_local_anc_onto_1cM_windows
        3       plot_admix_times
        1       plot_bootstrap_anc_by_r
        2       plot_mean_anc
        2       plot_shared_peaks
        2       plot_slope_elev
        2       simulate_MVN
        84      summarise_local_anc_by_1cM
        84      summarise_posterior
        1421
      hilo$ snakemake --touch all --quiet --profile slurm # 10.27.2020
      hilo$ snakemake -n all --quiet --profile slurm
      Job counts:
              count   jobs
              1       all
              2       plot_mean_anc
              2       plot_slope_elev
              5 # run just these ones that must be updated not with simply 'touch'
# testing 1 window for allopatric_maize:
hilo$ snakemake ancestry_by_r/results/f4/allopatric_maize/W1.abbababa2 --quiet --profile slurm
Job counts:
        count   jobs
        1       do_abba_baba
        1       input_abba_baba
        2 # see how many minutes it takes.. only 1.5min (not so bad!)
# now rerunning pop361, allopatric_maize, sympatric_maize as a group (and later will run sympatric mexicana)
hilo$ snakemake some --quiet --profile slurm # RUNNING 10.27.2020 5:23pm. oops actually got stuck on DAG b/c of wildcards for sympatric maize
hilo$ snakemake some --quiet --profile slurm # RUNNING 10.27.2020 8:39pm
Job counts:
        count   jobs
        3046    do_abba_baba
        1       input_abba_baba
        1       some
        3048
# MOST JOBS ARE RUNNING OUT OF TIME, BUT HAVE LOW CPU TIME
# AND VERY HIGH WALL TIME. I WANT TO ASK JEFF ABOUT THIS:
# W1:
# hilo$ less snake_logs/do_abba_baba.POP=allopatric_maize,WINDOW=W1.26676305.err
# Number of sites retained after filtering: 383460
# [ALL done] cpu-time used =  88.11 sec
# [ALL done] walltime used =  109.00 sec
# 1 of 1 steps (100%) done
# # ~60k lines in .err file
# slurm .out file:
# Reserved walltime   : 04:00:00
# Used walltime       : 00:01:53
# Used CPU time       : 00:01:29

# W1351:
# hilo$ less snake_logs/do_abba_baba.POP=allopatric_maize,WINDOW=W1351.26677882.err
# Number of sites retained after filtering: 1364706
# [ALL done] cpu-time used =  151.76 sec
# [ALL done] walltime used =  9801.00 sec
# slurmstepd: error: *** JOB 26677882 ON c6-67 CANCELLED AT 2020-10-28T00:32:43 DUE TO TIME LIMIT ***
# ~60k lines in .err file
# slurm .out file:
# Reserved walltime   : 04:00:00
# Used walltime       : 04:00:39
# Used CPU time       : 00:02:32
# note: this job times out nearly an hour after angsd thinks it's completed.

# SOLUTION: split whole genome bams into much smaller bams! (1 bam per 1cM segment). I can also re-header/re-sort and, if I want, cap with BAQ, when I do this.
# 1st check how much space I have in my dir on farm for duplicating bams.

# trying just 1 abbababa (with low r, so large region):
hilo$ snakemake ancestry_by_r/results/f4/allopatric_maize/W1331.abbababa2 --quiet --profile slurm
57399486 - ran out of memory
36294779-82156624

# what is the reading/writing capacity?
# try 5 short jobs at the same time:
hilo$ snakemake ancestry_by_r/results/f4/allopatric_maize/W34.abbababa2 ancestry_by_r/results/f4/allopatric_maize/W1442.abbababa2 ancestry_by_r/results/f4/allopatric_maize/W254.abbababa2 ancestry_by_r/results/f4/allopatric_maize/W253.abbababa2 ancestry_by_r/results/f4/allopatric_maize/W610.abbababa2 --quiet --profile slurm
Job counts:
        count   jobs
        5       do_abba_baba
        5 # RUNNING 10.29.2020. Finished fast in < 5min.
# ok, what about 10 jobs of cM/Mb bin 4? (so slightly bigger?)
hilo$ snakemake ancestry_by_r/results/f4/allopatric_maize/W611.abbababa2 ancestry_by_r/results/f4/allopatric_maize/W174.abbababa2 ancestry_by_r/results/f4/allopatric_maize/W175.abbababa2 ancestry_by_r/results/f4/allopatric_maize/W628.abbababa2 ancestry_by_r/results/f4/allopatric_maize/W629.abbababa2 ancestry_by_r/results/f4/allopatric_maize/W648.abbababa2 ancestry_by_r/results/f4/allopatric_maize/W649.abbababa2 ancestry_by_r/results/f4/allopatric_maize/W680.abbababa2
ancestry_by_r/results/f4/allopatric_maize/W1346.abbababa2 ancestry_by_r/results/f4/allopatric_maize/W1466.abbababa2 --quiet --profile slurm
Job counts:
        count   jobs
        10      do_abba_baba
        10 # RUNNING 10.29.2020. Takes about double walltime (6-7min) as cpu time (~3min).
# now try only 5 jobs at once from the bin 4 cM/Mb:
hilo$ Job counts:
        count   jobs
        5       do_abba_baba
        5 # RUNNING 10.29.2020. Not too much extra walltime -- only 20s per job.
# So ~5 jobs accessing the same files is a computational limit for I/O efficiency.
# Now checking that sympatric_maize runs equally smoothly with similar time/memory constraints:
hilo$ snakemake ancestry_by_r/results/f4/sympatric_maize/W199.abbababa2 ancestry_by_r/results/f4/sympatric_maize/W263.abbababa2 ancestry_by_r/results/f4/sympatric_maize/W270.abbababa2 ancestry_by_r/results/f4/sympatric_maize/W271.abbababa2 ancestry_by_r/results/f4/sympatric_maize/W272.abbababa2 --quiet --profile slurm
Job counts:
        count   jobs
        5       do_abba_baba
        1       input_abba_baba
        6 # RUNNING 10.29.2020
# can I limit the jobs in the snake command?
hilo$ snakemake ancestry_by_r/results/f4/sympatric_mexicana/W199.abbababa2 ancestry_by_r/results/f4/sympatric_mexicana/W263.abbababa2 ancestry_by_r/results/f4/sympatric_mexicana/W270.abbababa2 ancestry_by_r/results/f4/sympatric_mexicana/W271.abbababa2 --quiet --profile slurm --jobs 2
Job counts:
        count   jobs
        4       do_abba_baba
        1       input_abba_baba
        5 # try limiting to 2 running jobs at a time. Works!
        # so I just have to add the --jobs 5 flag when I run snakemake :)
# last test before running all:
hilo$ snakemake ancestry_by_r/results/f4/sympatric_maize/W309.abbababa2 ancestry_by_r/results/f4/allopatric_maize/W310.abbababa2 --quiet --profile slurm --jobs 1 --restart-times 1
Job counts:
        count   jobs
        2       do_abba_baba
        2 # RAN SMOOTHLY. 10.29.2020 5:40pm.
# now run rule 'some' has allopatric_maize, sympatric_maize, sympatric_mexicana. I estimate 24hrs to run per group.
hilo$ snakemake -n some --quiet --profile slurm --jobs 5
# mystery error keepincomplete=keep_incomplete fixed  ...
raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
Fixed by deleting some of the output files that maybe were from cancelled jobs (?)
Now running:
hilo$ snakemake -n some --quiet --profile slurm --jobs 5
Job counts:
        count   jobs
        4528    do_abba_baba
        1       some
        4529 # STARTED 10.29.2020 8:36pm. hmm, I'd prefer that it start with
        # allopatric_maize, then sympatric_maize. Will cancel and restart with just those 2:
# status when I cancelled the snakemake job:
hilo$ squeue -u ecalfee
         JOBID PARTITION     NAME     USER ST        TIME  NODES CPU MIN_ME NODELIST(REASON)
      26725636     high2     bash  ecalfee  R       47:30      1 1   2G     c6-92
      26726207      med2 do_abba_  ecalfee  R        6:29      1 2   7G     c6-92
      26726147      med2 do_abba_  ecalfee  R       11:24      1 2   5G     c6-92
      26726035      med2 do_abba_  ecalfee  R       19:01      1 2   6G     c6-92
      26725668      med2 do_abba_  ecalfee  R       35:37      1 2   6G     c6-92
      26725673      med2 do_abba_  ecalfee  R       35:37      1 3   8G     c6-92
      # then cancelled remaining running jobs (1 finished, but maybe created bad files)
      hilo$ scancel 26726207 26726147 26726035 26725673
hilo$ snakemake some --quiet --profile slurm --jobs 5
Job counts:
        count   jobs
        3012    do_abba_baba
        1       some
        3013 # RUNNING 10.29.2020 9:30pm. Order is random .. here it's starting with sympatric_maize regions.
# to find out which file is running, e.g.
hilo$ grep 'wildcards:' -A 1 snake_logs/*abba*26726313.err
# so all but 6 abba baba files ran .. mostly seems like by Saturday morning.
# some were rerun because of memory & I'm checking right now the ones that didn't complete:
hilo$ snakemake -n some --quiet --profile slurm --jobs 5
Job counts:
        count   jobs
        6       do_abba_baba
        1       some
        7
# which files are missing?
hilo$ for i in {1..1520}; do ls ancestry_by_r/results/f4/allopatric_maize/W$i.abbababa2; done | grep 'cannot'
ls: cannot access 'ancestry_by_r/results/f4/allopatric_maize/W113.abbababa2': No such file or directory
ls: cannot access 'ancestry_by_r/results/f4/allopatric_maize/W892.abbababa2': No such file or directory
ls: cannot access 'ancestry_by_r/results/f4/allopatric_maize/W1264.abbababa2': No such file or directory
# same ones from sympatric_maize too
# memory not enough: 12G, 13G, 12G
# I added memory so it starts at 8G + extra , then goes to 16G + extra, then 24G + extra on attempt 3
hilo$ snakemake some --quiet --profile slurm --jobs 5
# running Sunday Nov 1 8:50pm
# W892 still ran out of memory. Time is very dependent on region length, but not memory.
hilo$ snakemake ancestry_by_r/results/f4/allopatric_maize/W892.abbababa2 ancestry_by_r/results/f4/sympatric_maize/W892.abbababa2 --quiet --profile slurm --jobs 5 --restart-times 0 --config mem=32G
Job counts:
        count   jobs
        2       do_abba_baba
        2 # RUNNING 11.1.2020 10:36pm. CANCELLED BECAUSE DIDN'T USE THE 32G of memory.
# I changed to each job having 8, 16, or 32G memory
# added in sympatric_mexicana and pop361 to run abba baba (can do other pops later if needed)

hilo$ snakemake some --quiet --profile slurm --jobs 5
Job counts:
        count   jobs
        1521    do_abba_baba
        1       some
        1522 # RUNNING 11.1.2020 11:30pm. Note: W892 still hasn't completed.
# cancelled with just a few that didn't run/stalled Nov 2 at 11pm. Adding memory up to 40G for 3rd attempt.
# also adding in a population to test that pattern holds also at individual population level.
hilo$ snakemake some --quiet --profile slurm --jobs 5 # RUNNING 11.3.2020 1am
# sympatric_maize and sympatric_mexicana still ran out of memory with 40G for W892, so now rerunning just those
# with 48G, 64G, 80G attempts. Will see how much memory they use.
hilo$ snakemake some --quiet --profile slurm --jobs 5 # RUNNING 11.3.2020 1am
Job counts:
        count   jobs
        2       do_abba_baba
        1       some
        3 # completed quickly with between 40 and 48G memory usage.

# testing ANGSD D-STAT to find out order of abbababa2 output file:
hilo$ Rscript ../software/angsd_0.932/R/estAvgError.R angsdFile="ancestry_by_r/results/f4/sympatric_maize/W1" out="test_Dstat" sizeFile="ancestry_by_r/results/f4/sympatric_maize.size"

# installed R package pracma
hilo$ Rscript ../software/angsd_0.932/R/estAvgError.R angsdFile="ancestry_by_r/results/f4/sympatric_maize/W1" out="test_Dstat" sizeFile="ancestry_by_r/results/f4/sympatric_maize.size" nameFile="ancestry_by_r/results/f4/sympatric_maize.names"
----------
angsdFile:  ancestry_by_r/results/f4/sympatric_maize/W1   errFile:  FALSE  nameFile:  ancestry_by_r/results/f4/sympatric_maize.names  sizeFile:  ancestry_by_r/results/f4/sympatric_maize.size  out:  test_Dstat  addErr:  FALSE  nIter:  100 maxErr:  0.02
-----------
--- Building tree error matrices ---
 --- Time Spent  0  sec
Error in `colnames<-`(`*tmp*`, value = colnames(outDataTotal)) :
  attempt to set 'colnames' on an object with less than two dimensions
Execution halted
# maybe it needs more than 1 region to run calcs:
hilo$ cat ancestry_by_r/results/f4/sympatric_maize/W1.abbababa2 > test_W1-9_sympatric_maize.abbababa2
hilo$ cat ancestry_by_r/results/f4/sympatric_maize/W1.abbababa2 > test_W1-100_sympatric_maize.abbababa2
ecalfee@c6-67:~/hilo$ for i in {2..100}; do tail -n 3 ancestry_by_r/results/f4/sympatric_maize/W$i.abbababa2 >> test_W1-100_sympatric_maize.abbababa2; done
ecalfee@c6-67:~/hilo$ Rscript ../software/angsd_0.932/R/estAvgError.R angsdFile="test_W1-100_sympatric_maize" out="test_Dstat_W1-100_sympatric_maize" sizeFile="ancestry_by_r/results/f4/sympatric_maize.size" nameFile="ancestry_by_r/results/f4/sympatric_maize.names"

hilo/ancestry_by_r/results/f4$ for i in {890..893}; do head -n 2 sympatric_maize/W$i.abbababa2 | tail -n 1 | cut -f1,4-6; done
6	-3.199246	459.730621	57905.000000
6	-14.845173	921.008586	216003.000000
head: cannot open 'sympatric_maize/W892.abbababa2' for reading: No such file or directory
6	-86.311113	1830.236866	371792.000000

# skipping W892 for now. summarising f4s. sympatric_maize.1.f4 is line 1 results, .2.f4 is line 2 results etc.
# only population orders change:
ecalfee@c6-67:~/hilo$ (head -n 1 ancestry_by_r/results/f4/allopatric_maize/W1.abbababa2 | cut -f1-6 | awk '{print "window" "\t" $0 "\t" "pop1" "\t" "pop2" "\t" "pop3" "\t" "pop4"}'; for i in {1..891} {893..1520}; do tail -n +2 ancestry_by_r/results/f4/allopatric_maize/W$i.abbababa2 | cut -f1-6| awk -v i=$i 'NR%3==1 {print "W"i "\t" $0 "\t" "parviglumis" "\t" "allopatric_mexicana" "\t" "allopatric_maize" "\t" "tripsacum"}';  done) > ancestry_by_r/results/f4/allopatric_maize.1.f4

# all the other files too:
ecalfee@c6-67:~/hilo$ (head -n 1 ancestry_by_r/results/f4/allopatric_maize/W1.abbababa2 | cut -f1-6 | awk '{print "window" "\t" $0 "\t" "pop1" "\t" "pop2" "\t" "pop3" "\t" "pop4"}'; for i in {1..891} {893..1520}; do tail -n +2 ancestry_by_r/results/f4/allopatric_maize/W$i.abbababa2 | cut -f1-6| awk -v i=$i 'NR%3==2 {print "W"i "\t" $0 "\t" "parviglumis" "\t" "allopatric_mexicana" "\t" "allopatric_maize" "\t" "tripsacum"}';  done) > ancestry_by_r/results/f4/allopatric_maize.2.f4
ecalfee@c6-67:~/hilo$ (head -n 1 ancestry_by_r/results/f4/allopatric_maize/W1.abbababa2 | cut -f1-6 | awk '{print "window" "\t" $0 "\t" "pop1" "\t" "pop2" "\t" "pop3" "\t" "pop4"}'; for i in {1..891} {893..1520}; do tail -n +2 ancestry_by_r/results/f4/allopatric_maize/W$i.abbababa2 | cut -f1-6| awk -v i=$i 'NR%3==0 {print "W"i "\t" $0 "\t" "parviglumis" "\t" "allopatric_mexicana" "\t" "allopatric_maize" "\t" "tripsacum"}';  done) > ancestry_by_r/results/f4/allopatric_maize.3.f4

ecalfee@c6-67:~/hilo$ (head -n 1 ancestry_by_r/results/f4/sympatric_maize/W1.abbababa2 | cut -f1-6 | awk '{print "window" "\t" $0 "\t" "pop1" "\t" "pop2" "\t" "pop3" "\t" "pop4"}'; for i in {1..891} {893..1520}; do tail -n +2 ancestry_by_r/results/f4/sympatric_maize/W$i.abbababa2 | cut -f1-6| awk -v i=$i 'NR%3==1 {print "W"i "\t" $0 "\t" "parviglumis" "\t" "allopatric_mexicana" "\t" "sympatric_maize" "\t" "tripsacum"}';  done) > ancestry_by_r/results/f4/sympatric_maize.1.f4
ecalfee@c6-67:~/hilo$ (head -n 1 ancestry_by_r/results/f4/sympatric_maize/W1.abbababa2 | cut -f1-6 | awk '{print "window" "\t" $0 "\t" "pop1" "\t" "pop2" "\t" "pop3" "\t" "pop4"}'; for i in {1..891} {893..1520}; do tail -n +2 ancestry_by_r/results/f4/sympatric_maize/W$i.abbababa2 | cut -f1-6| awk -v i=$i 'NR%3==2 {print "W"i "\t" $0 "\t" "parviglumis" "\t" "allopatric_mexicana" "\t" "sympatric_maize" "\t" "tripsacum"}';  done) > ancestry_by_r/results/f4/sympatric_maize.2.f4
ecalfee@c6-67:~/hilo$ (head -n 1 ancestry_by_r/results/f4/sympatric_maize/W1.abbababa2 | cut -f1-6 | awk '{print "window" "\t" $0 "\t" "pop1" "\t" "pop2" "\t" "pop3" "\t" "pop4"}'; for i in {1..891} {893..1520}; do tail -n +2 ancestry_by_r/results/f4/sympatric_maize/W$i.abbababa2 | cut -f1-6| awk -v i=$i 'NR%3==0 {print "W"i "\t" $0 "\t" "parviglumis" "\t" "allopatric_mexicana" "\t" "sympatric_maize" "\t" "tripsacum"}';  done) > ancestry_by_r/results/f4/sympatric_maize.3.f4


# D - stats all windows but 892:
hilo$ (cat ancestry_by_r/results/f4/sympatric_maize/W1.abbababa2; for i in {2..891} {893..1520}; do tail -n +2 ancestry_by_r/results/f4/sympatric_maize/W$i.abbababa2; done) > ancestry_by_r/results/f4/sympatric_maize.all.abbababa2
hilo$ Rscript ../software/angsd_0.932/R/estAvgError.R angsdFile="ancestry_by_r/results/f4/sympatric_maize.all" out="ancestry_by_r/results/f4/sympatric_maize.Dstats" sizeFile="ancestry_by_r/results/f4/sympatric_maize.size" nameFile="ancestry_by_r/results/f4/sympatric_maize.names"
hilo$ (cat ancestry_by_r/results/f4/allopatric_maize/W1.abbababa2; for i in {2..891} {893..1520}; do tail -n +2 ancestry_by_r/results/f4/allopatric_maize/W$i.abbababa2; done) > ancestry_by_r/results/f4/allopatric_maize.all.abbababa2
hilo$ Rscript ../software/angsd_0.932/R/estAvgError.R angsdFile="ancestry_by_r/results/f4/allopatric_maize.all" out="ancestry_by_r/results/f4/allopatric_maize.Dstats" sizeFile="ancestry_by_r/results/f4/allopatric_maize.size" nameFile="ancestry_by_r/results/f4/allopatric_maize.names"
# results have format: sympatric_maize.Dstats.Observed.txt

# hmm.. seems like the blocks didn't work quite how I expected
# some files have 7 lines instead of 4 because windows span multiple blocks:
hilo$ nano ancestry_by_r/results/f4/sympatric_maize/W95.abbababa2
W95: 1       119583369       154171190

# making the code above into snakemake rules and rerunning:
hilo$ snakemake some --quiet --profile slurm
# can't set attribute error line 417 (run D-stat rule). Trying to fix syntax of shell command.
# I think it was because I can't set 'size' or possible 'names' as a named input file. Fixed!
hilo$ snakemake some --quiet --profile slurm
Job counts:
        count   jobs
        5       calc_Dstat
        5       combine_abba_baba_for_Dstat
        5       f4_from_abba_baba
        1       some
        16 # RUNNING 11.3.2020 11:37am. Hm says some issue with POP wildcard? fixing by adding to params.
# adding 2 more individual maize pops from across the range for f4 stats: pop362 & 366 (Santa Clara & Jicaltepec)
hilo$ snakemake some --quiet --profile slurm --jobs 5
# RUNNING 11.3.2020

# had typo in rule (fixed) but to run quickly I just did in command line:
hilo$ (head -n 1 ancestry_by_r/results/f4/sympatric_maize/W1.abbababa2 | cut -f1-6 | awk -v OFS="\t" '{print "window",$0,"pop1","pop2","pop3","pop4"}'; for i in {1..1520}; do tail -n +2 ancestry_by_r/results/f4/sympatric_maize/W$i.abbababa2 | cut -f1-6 | awk -v i=$i -v pop=sympatric_maize -v OFS="\t" 'NR%3==1 {print "W"i,$0,"parviglumis","allopatric_mexicana",pop,"tripsacum"}'; done) > ancestry_by_r/results/f4/sympatric_maize.f4

# trying out making fasta file for tripsacum (test on small region):
hilo$ snakemake filtered_bams/results/SRR7758238/TRIP.sort.dedup.baq.fasta --quiet --profile slurm
Job counts:
        count   jobs
        1       make_fasta
        1 # didn't work. (different output format). Trying again on small region:
        hilo$ snakemake filtered_bams/results/SRR7758238/TRIP.fa.gz --quiet --profile slurm
        Job counts:
                count   jobs
                1       make_fasta
                1. COMPLETED. Now removing output file and fixing rule to run on whole genome.

# decided to make f4's with Amecameca (pop22) instead of using all allopatric mexicana
# because this population has no evidence of admixture.
hilo$ snakemake -n all --quiet --profile slurm --jobs 6
# missing samples/ALL_byPop/pop22_bams.list b/c apparently only copied over sympatric pop lists.
# copied over pop20, pop22 and pop33 to ALL_byPop. Unfortunately tried to use a for loop for samples/Over0.5x/byPop and it copied ALL pop files, including sympatric. oops!
# this will trigger a big re-run :(
for i in 20 22 33; do scp -P 2022 samples/Over0.5x_byPop/pop$i_*.list ecalfee@farm.cse.ucdavis.edu:~/hilo/samples/Over0.5x_byPop/.; done
# so I will try to 'touch' on snakemake to not rerun all the local ancestry rules etc.
# should take a min to ID what files need to be 'touched' to fix this .. :/
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        84      boot_ancestry_hmm
        2       calc_K_matrix_zea
        6       combine_pop_ancestry_data
        2       fdr_zAnc
        2       fit_lm_elev
        2       fit_zAnc
        84      get_admix_times
        56      get_homozygous_ancestry_bams
        56      get_homozygous_ancestry_tracts
        28      get_maximum_a_posterior
        28      make_input_hmm
        84      map_local_anc_onto_1cM_windows
        3       plot_admix_times
        1       plot_bootstrap_anc_by_r
        2       plot_mean_anc
        2       plot_shared_peaks
        2       plot_slope_elev
        2       simulate_MVN
        84      summarise_local_anc_by_1cM
        84      summarise_posterior
        615
# run 'touch' to update timestamps for all outputs:
hilo$ snakemake --touch all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        84      boot_ancestry_hmm
        2       calc_K_matrix_zea
        6       combine_pop_ancestry_data
        2       fdr_zAnc
        2       fit_lm_elev
        2       fit_zAnc
        84      get_admix_times
        56      get_homozygous_ancestry_bams
        56      get_homozygous_ancestry_tracts
        28      get_maximum_a_posterior
        28      make_input_hmm
        84      map_local_anc_onto_1cM_windows
        3       plot_admix_times
        1       plot_bootstrap_anc_by_r
        2       plot_mean_anc
        2       plot_shared_peaks
        2       plot_slope_elev
        2       simulate_MVN
        84      summarise_local_anc_by_1cM
        84      summarise_posterior
        615
# check nothing else needs to be re-run:
hilo$ snakemake -n all --quiet --profile slurm
(all clear)
# then try again to redo f4s and make tripsacum fasta:
hilo$ snakemake -n all --quiet --profile slurm --jobs 6
Job counts:
        count   jobs
        1       all
        3       calc_Dstat
        3       combine_abba_baba_for_Dstat
        4560    do_abba_baba
        3       f4_from_abba_baba
        3       input_abba_baba
        1       make_fasta
        4574 # RUNNING 11.13.2020 4:19pm
        hilo$ squeue -u ecalfee
                 JOBID PARTITION     NAME     USER ST        TIME  NODES CPU MIN_ME NODELIST(REASON)
              26997260     high2     bash  ecalfee  R       17:54      1 1   2G     c6-95
              26997750      med2 do_abba_  ecalfee  R        0:21      1 3   8G     c6-96
              26997744      med2 do_abba_  ecalfee  R        0:43      1 3   8G     c6-94
              26997745      med2 do_abba_  ecalfee  R        0:43      1 3   8G     c6-94
              26997743      med2 do_abba_  ecalfee  R        0:46      1 3   8G     c6-95
              26997712      med2 make_fas  ecalfee  R        2:05      1 13  48G    c6-94
# everything but summary files and Dstats ran. Couldn't find snake logs, so just trying these files again:
hilo$ snakemake all --quiet --profile slurm --jobs 6
Job counts:
    count   jobs
    1       all
    3       calc_Dstat
    3       combine_abba_baba_for_Dstat
    3       f4_from_abba_baba
    10 # RUNNING 11.16.2020 12pm. hmm, getting weird error:
    RuleException in line 353 of /home/ecalfee/hilo/ancestry_by_r/Snakefile:
    IndexError: list index out of range # fixed problem -- needed double brackets in for i in {{1..1250}}
hilo$ snakemake all --quiet --profile slurm
# RUNNING 11.16.2020 9:12pm. oops fixed 2nd for loop {{}} too. Fixed {POP} to {params.POP} in next rule.
# added a bunch of rules to the pipeline to look at flowering time genes.
# flowering time genes
# downloaded Data S7 candidate genes compiled by Li et al 2016
data/flowering_time/candidate_flowering_time_genes_Li_et_al_2016_data_S7.csv
# copy-pasted first column (gene name) into new file
data/flowering_time/v2_gene_names_Li_et_al_2016.csv
# found unique gene names
Erin$ cat data/flowering_time/v2_gene_names_Li_et_al_2016.csv | sort | uniq  > data/flowering_time/v2_unique_gene_names_Li_et_al_2016.csv
# download gene model cross reference from GRAMENE:
https://www.maizegdb.org/gene_center/gene#ncbi
(Complete B73 v4 (Zm00001d.2) gene model cross reference)
data/refMaize/geneAnnotations/gene_model_xref_v4_from_gramene.txt

hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       add_10kb_flowering_time_genes
        1       all
        3       calc_Dstat
        3       calc_and_plot_f4
        24      calc_overlap
        3       combine_abba_baba_for_Dstat
        2       f4_from_abba_baba
        1       find_flowering_time_genes_v4
        2       fit_lm_elev
        2       make_bed_anc_outliers
        2       make_bed_slope_elev
        24      merge_bed_outliers
        2       plot_slope_elev
        70 # 11.20.2020: RUNNING 11:23pm. Many jobs didn't run:
        hilo$ snakemake -n all --quiet --profile slurm
        Job counts:
                count   jobs
                1       all
                3       calc_Dstat # error is I must have accidentally written over angsd DStat script with a blank script. will download new one. (ls -lh says: -rw-r--r-- 1 ecalfee ecalfee    0 Nov 12 14:58 ../software/angsd_0.932/R/estAvgError.R)
                3       calc_and_plot_f4 # error: inv_file must be character string or connection -fixed.
                24      calc_overlap
                2       make_bed_anc_outliers # error: fdr_pos file not found (to write to)
                2       make_bed_slope_elev # fixed output file name errors in R script.
                24      merge_bed_outliers
                59 # trying again. RUNNING 10:26am 11.23.2020. Oops still some errors. fixed make_bed_slope_outliers but still troubleshooting calc_and_plot_f4
                /hilo$ snakemake all --quiet --profile slurm
                Job counts:
                        count   jobs
                        1       all
                        2       calc_and_plot_f4
                        12      calc_overlap
                        2       make_bed_slope_elev
                        12      merge_bed_outliers
                        29 # RUNNING 11.24.2020 11:55am
# problem with errors in calc_and_plot_f4:
`summarise()` regrouping output by 'bin_cd5' (override with `.groups` argument)
Error: Aesthetics must be either length 1 or the same as the data (5000): colour
Backtrace: ggplot2. # I fixed a problem with 'zea' variable being NA. rerunning:
# COMPLETED.
Oops I switched around my f4 populations for the f4 ratio. I'm rerunning these analyses f4(trip, parv; X, allo_maize)
where X is a sympatric population (numerator) or allopatric mexicana (pop 22 = Amecameca, denominator)
# new files will be in output directory f4/ . I have moved all previous f4's in this folder to a new folder f4_allopatric_mexicana/
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        3       calc_Dstat
        2       calc_and_plot_f4
        3       combine_abba_baba_for_Dstat
        4560    do_abba_baba
        3       f4_from_abba_baba
        3       input_abba_baba
        4575 # RUNNING 11.25.2020 2:15pm. CANCELLED because forgot to limit --jobs to just 6. rerunning:
b/c I cancelled jobs I had to 'unlock' the directory to rerun snakemake:
Error: Directory cannot be locked. Please make sure that no other Snakemake process is trying to create the same files in the following directory:
/home/ecalfee/hilo
If you are sure that no other instances of snakemake are running on this directory, the remaining lock was likely caused by a kill signal or a power loss. It can be removed with the --unlock argument.
(hilo-env) ecalfee@farm:~/hilo$ snakemake all --quiet --profile slurm --jobs 5 --unlock
# Note: should just do snakemake --unlock I think next time!! Doesn't run when you use --unlock
ecalfee@farm:~/hilo$ snakemake all --quiet --profile slurm --jobs 5
# still running, but moving on to sympatric_maize from mexicana. will check on one missing files:
hilo$ for i in {1..1520}; do ls ancestry_by_r/results/f4/sympatric_mexicana/*W$i.abbababa2; done
ls: cannot access 'ancestry_by_r/results/f4/sympatric_mexicana/*W635.abbababa2': No such file or directory
OOPS ran out of time on this one. Will need to rerun after with extra time:
ecalfee@c6-89:~/hilo$ tail snake_logs/do_abba_baba.POP=sympatric_mexicana,WINDOW=W635.27964807.out
End                 : 2020-11-30T04:29:32
Reserved walltime   : 02:38:00
Used walltime       : 02:38:10
# FARM had some kind of 16hr downtime (?). My screen and jobs all stopped... just logged back in Dec 2, 1pm
ecalfee@farm:~/hilo$ snakemake all --quiet --profile slurm --jobs 6
Job counts:
        count   jobs
        1       all
        3       calc_Dstat
        2       calc_and_plot_f4
        3       combine_abba_baba_for_Dstat
        2208    do_abba_baba
        3       f4_from_abba_baba
        2220 # RUNNING 12/2/2020 1:20pm. Weird it only ran like 100 jobs then quit.
        # like the snakemake run just stopped. So I'm starting snakemake again:
        hilo$ snakemake all --quiet --profile slurm --jobs 5
        Job counts:
                count   jobs
                1       all
                3       calc_Dstat
                2       calc_and_plot_f4
                3       combine_abba_baba_for_Dstat
                2100    do_abba_baba
                3       f4_from_abba_baba
                2112 12/2/2020 10:45pm
hilo$ snakemake all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        2       calc_Dstat
        2       calc_and_plot_f4
        2       combine_abba_baba_for_Dstat
        2       do_abba_baba
        2       f4_from_abba_baba
        11 # running 12.9.2020 . Checked in on Dec 11 and weirdly looks like it got frozen and didn't run through. so stopped & re-started same command:
        hilo$ snakemake all --quiet --profile slurm
        Job counts:
                count   jobs
                1       all
                1       calc_Dstat
                1       calc_and_plot_f4
                1       combine_abba_baba_for_Dstat
                1       do_abba_baba
                1       f4_from_abba_baba
                6 # running 12.11.2020. Abba-baba is job 28550210 for W635 sympatric_mexicana

# making input bams lists:
# test one:
hilo$ snakemake local_ancestry/results/ancestry_hmm/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/bams/pop363_bams.list --quiet --profile slurm --restart-times 0
Job counts:
        count   jobs
        1       index_and_list_homozygous_ancestry_bams
        1 # grr there is something wrong with the input bams! they are empty :(
        # I fixed file naming error in get_homozygous_ancestry_bams.sh script.
        # also deleting 'completed' files for bams so they are re-run.
        hilo$ rm local_ancestry/results/ancestry_hmm/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/*/bams/*.completed
# re-run them all to make bams and then also create input bams lists:
Job counts:
        count   jobs
        1       all
        56      get_homozygous_ancestry_bams
        56      list_homozygous_ancestry_bams
        113 # RUNNING 12.29.2020 1:26pm

# some missing files: pop18, pop23, pop28, pop29, pop34 for maize ancestry bams list.
# weird that it's a timeout error for such a small task (echo)
# I'll just rerun without edits .. maybe some issue with the computer nodes
hilo$ snakemake all --quiet --profile slurm                                      Job counts:
        count   jobs
        1       all
        14      list_homozygous_ancestry_bams
        15 # RUNNING 12.31.2020 5pm


## Get pi estimates within homozygous ancestry across the whole genome.
# - test pi script with small genome segment. then decide memory for running a whole pop.
# trying out pipeline to get pi estimates across the genome for each population within homozygous ancestry segments
# test pipeline using a small 500 kb test region on chr1
hilo$ snakemake diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.thetas.gz --quiet --profile slurm
hilo$ snakemake diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.thetas.gz --quiet --profile slurm
Job counts:
        count   jobs
        1       calc_thetas
        1       estimate_saf_pop
        1       estimate_sfs
        3 # RUNNING 1.1.2021 12:30pm. Fixed the double .. in file extension output and re-trying:

hilo$ snakemake diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.thetas.gz --quiet --profile slurm --restart-times 0
# estimate_saf_pop took ~15sec and esitmate_sfs took ~10sec computing time for .5Mb ..
# so scaling that to whole genome is about 18 hrs and 12 hrs based on scaling up to 2.2Tb
# calc_thetas failed:
Problem opening file: 'diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.saf.gz'
# hilo$ realSFS saf2theta diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.saf.idx -sfs diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.sfs -outname diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small
	-> Version of fname:diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.saf.idx is:2
	-> Assuming .saf.gz file: diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.saf.gz
	-> Assuming .saf.pos.gz: diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.saf.pos.gz
	-> args: tole:0.000001 nthreads:4 maxiter:100 nsites:0 start:diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.sfs chr:(null) start:-1 stop:-1 fstout:diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small oldout:0 seed:1609607311 bootstrap:0 resample_chr:0 whichFst:0 fold:0 ref:(null) anc:(null)
	-> Will read chunks of size: 4096
	-> Reading: diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.sfs assuming counts (will normalize to probs internally)
File:diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.sfs looks empty
# the sfs file is empty!! But that rule runs fine manually when I create sfs in command line..
Deleted intermediate files and running test again:
hilo$ snakemake diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.thetas.gz --quiet --profile slurm --restart-times 0
Job counts:
        count   jobs
        1       calc_thetas
        1       estimate_saf_pop
        1       estimate_sfs
        3 # 1.2.2020. calc_thetas rule didn't run!
        # errors:
        -> Version of fname:diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.saf.gz is:2
        /bin/bash: line 1: 41159 Segmentation fault      realSFS saf2theta diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.saf.gz -sfs diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.sfs -outna$
# ok so I fixed .saf.gz -> .saf.idx typo. Now I need to figure out what's wrong with .sfs file:
File:diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.sfs looks empty

# hmm... in rule estimate_sfs logs I have this error:
Problem opening file: 'diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.saf.gz
# and it keeps giving me a warning about version fname is 2:
Version of fname:diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.saf.idx is:2
# got rid of 'shadow' for these rules, deleted all intermediate output files, and restarting snakemake:
hilo$ rm diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.*
hilo$ snakemake diversity/results/pi/HILO_MAIZE55/Ne10000_yesBoot/HOMOZYG/maize/pop362.small.thetas.gz --quiet --profile slurm --restart-times 0
Job counts:
        count   jobs
        1       calc_thetas
        1       estimate_saf_pop
        1       estimate_sfs
        3 # ran through!! Now figure out best resources/timing for whole genome. removed all 'small' and genome segment/regions portions of code to run on full genome.         #"-r 1:1000000-1500000 "
        (hilo-env) ecalfee@farm:~/hilo$ snakemake all --quiet --profile slurm
        Job counts:
                count   jobs
                1       all
                56      calc_thetas
                56      estimate_saf_pop
                56      estimate_sfs
                56      get_homozygous_ancestry_bams
                56      get_homozygous_ancestry_tracts
                56      list_homozygous_ancestry_bams
                337 # RUNNING 1.4.2020. some ran out of memory for estimate_saf_pop. so I'm increasing and rerunning:
                hilo$ snakemake all --quiet --profile slurm
                Job counts:
                        count   jobs
                        1       all
                        35      calc_thetas
                        35      estimate_saf_pop
                        35      estimate_sfs
                        4       list_homozygous_ancestry_bams
                        110 # 1.6.2020 9pm. some error could not assign memory. not sure issue but lessened total possible memory for 1 rule nad trying again.
                        hilo$ snakemake all --quiet --profile slurm
                        Job counts:
                                count   jobs
                                1       all
                                35      calc_thetas
                                35      estimate_saf_pop
                                35      estimate_sfs
                                4       list_homozygous_ancestry_bams
                                110
                        Traceback (most recent call last):
                          File "/home/ecalfee/.conda/envs/hilo-env/lib/python3.6/site-packages/snakemake/__init__.py", line 665, in snakemake
                            keepincomplete=keep_incomplete,
                          File "/home/ecalfee/.conda/envs/hilo-env/lib/python3.6/site-packages/snakemake/workflow.py", line 908, in execute
                            success = scheduler.schedule()
                          File "/home/ecalfee/.conda/envs/hilo-env/lib/python3.6/site-packages/snakemake/scheduler.py", line 378, in schedule
                            self.run(job)
                          File "/home/ecalfee/.conda/envs/hilo-env/lib/python3.6/site-packages/snakemake/scheduler.py", line 397, in run
                            error_callback=self._error,
                          File "/home/ecalfee/.conda/envs/hilo-env/lib/python3.6/site-packages/snakemake/executors.py", line 915, in run
                            shell=True,
                          File "/home/ecalfee/.conda/envs/hilo-env/lib/python3.6/subprocess.py", line 356, in check_output
                            **kwargs).stdout
                          File "/home/ecalfee/.conda/envs/hilo-env/lib/python3.6/subprocess.py", line 423, in run
                            with Popen(*popenargs, **kwargs) as process:
                          File "/home/ecalfee/.conda/envs/hilo-env/lib/python3.6/subprocess.py", line 729, in __init__
                            restore_signals, start_new_session)
                          File "/home/ecalfee/.conda/envs/hilo-env/lib/python3.6/subprocess.py", line 1295, in _execute_child
                            restore_signals, start_new_session, preexec_fn)
                        OSError: [Errno 12] Cannot allocate memory
                        # HMM.. problem with rule estimate_saf_pop on cluser, e.g. job 28893369
# pausing on this for a min to re-do some results for bootstrapping ancestry ~ r:
# first remove results
hilo$ rm ancestry_by_r/results/bootstrap_1cM/HILO_MAIZE55/*.Rdata
# then remake them:
hilo$ snakemake ancestry_by_r/results/bootstrap_1cM/HILO_MAIZE55/cd5_K2.Rdata ancestry_by_r/results/bootstrap_1cM/HILO_MAIZE55/r5_K2.Rdata --quiet --profile slurm
Job counts:
        count   jobs
        2       summarise_bootstrap_anc_by_r
        2 # RUNNING 1.9.2020 12:30pm. needed to add na.rm to quantiles after correlation
        # because one bootstrap sample for cd's within allopatric maize has no variance (all ancestry = 100% maize)
        # rerunning:
        snakemake ancestry_by_r/results/bootstrap_1cM/HILO_MAIZE55/cd5_K2.Rdata ancestry_by_r/results/bootstrap_1cM/HILO_MAIZE55/r5_K2.Rdata --quiet --profile slurm
        Job counts:
        count   jobs
        2       summarise_bootstrap_anc_by_r
        2 # completed
# Checking status of pi estimate scripts
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        2       calc_and_plot_f4
        22      calc_thetas
        22      estimate_saf_pop
        22      estimate_sfs
        1       plot_bootstrap_NGSadmix_by_r
        1       plot_bootstrap_local_ancestry_by_r
        71 # errors with calc_and_plot_f4 as well as estimates_saf_pop:
        Error in rule estimate_saf_pop -- attempt 1 ran out of memory (at 40G)
        angsd -out diversity/results/pi/HILO_MAIZE55/Ne100000_yesBoot/HOMOZYG/maize/pop19
        cluster_jobid: 29386913 # will wait to see if it's a larger problem across populations/attempts.
        Job counts:
                count   jobs
                1       all
                2       calc_and_plot_f4
                21      cqalc_thetas
                21      estimate_saf_pop
                21      estimate_sfs
                1       plot_bootstrap_NGSadmix_by_r
                1       plot_bootstrap_local_ancestry_by_r
                68 # trying again with more memory for estimate_saf_pop and an updated environment for R scripts. 1.19.2020 3pm

# error in calc_and_plot_f4: wrong filename from Snakefile (fixing)

# TO DO:
- test the 'domesticate assymmilate hypothesis' for mexicana.
- Figure out how you want to plot/analyze pi across the genome (re: outliers vs. background)
- set up FST calculations. Do FST between sympatric pairs, then estimate time/resources to do e.g. all 14*14 comparisons or sympatric * (all BUT sympatric)
- need to make a 'all pops but X list of individuals'
- look at admixture at known domestication genes
- flowering time -- should I look for a difference in avg slope not just enrichment of outliers?

# ASK IF THE EQUATION IN SORAGGI SHOULD HAVE A NEGATIVE IN THE NUMERATOR
# PREP FOR PRESENTATION:
# (1) Get list of flowering time GWAS hits and compare overlap. If time, at end, control for recombination rate using BEDTools
# (2) Plot maize vs. mexicana with domestication loci highlighted a different color
# Look quickly at results for zAnc -- anything interesting?
# (3) Plot K matrices
# (4) Anything on pi that you can salvage?
# (5) Do I keep anything on zTz? What do I want to conclude, just that idiosyncratic selection is more common?

# find flowering time GWAS hits and do permutations to calcuate overlap with big slopes w/ elevation
(5) Make plot of freq in maize vs. freq in mexicana
