# HMMM.... BENCHMARKS:
# how can I log how a task is doing??
--cluster-status ./status.py
# see example here: https://snakemake.readthedocs.io/en/stable/tutorial/additional_features.html
a 2.4G file only took 7hrs (24304seconds) real time, and 101 hrs (364921sec) cpu time
that's using 16 threads.
Max memory was <14G

what do I expect for samtools??

# HOW DO I STOP AND RESTART SNAKEMAKE?
# Can I restart failed jobs with double time and double memory? yes, done.
# I want to log cluster-status. skip for now.
OUT_OF_MEMORY CANCELLED STOPPED TIMEOUT FAILED
PENDING RUNNING COMPLETED COMPLETING SUSPENDED
--parsable #within cluster call . skip for now.
--cluster-status ./status.py #in profile
# test with a task that should run out of memory (give way too little)
# test also with a task that should run out of time (too little time)
# and some that should run through, but take a min or two
--max-status-checks-per-second 0.2

# can memory take in file size?
snakemake -n --quiet # will just print final summary


# I CANCELLED MY SCREEN SNAKEMAKE JOB WITH THESE PROCESSES LEFT TO RUN:
21567559   bigmemm bwa_map.  ecalfee  R     8:53:03      1 16  64G    bigmem8
21567566   bigmemm bwa_map.  ecalfee  R     1:41:03      1 16  64G    bigmem3
21567565   bigmemm bwa_map.  ecalfee  R     1:52:03      1 16  64G    bigmem7
21567563   bigmemm bwa_map.  ecalfee  R     3:58:50      1 16  64G    bigmem6
21567562   bigmemm bwa_map.  ecalfee  R     6:41:59      1 16  64G    bigmem7
21567573   bigmemm bwa_map.  ecalfee  R       14:04      1 16  64G    bigmem8
21567568   bigmemm bwa_map.  ecalfee  R     1:00:06      1 16  64G    bigmem5
21567569   bigmemm bwa_map.  ecalfee  R     1:00:06      1 16  64G    bigmem4
21567570   bigmemm bwa_map.  ecalfee  R     1:00:06      1 16  64G    bigmem4
21567571   bigmemm bwa_map.  ecalfee  R     1:00:06      1 16  64G    bigmem4
21567572   bigmemm bwa_map.  ecalfee  R     1:00:06      1 16  64G    bigmem4
21567567   bigmemm bwa_map.  ecalfee  R     1:04:13      1 16  64G    bigmem8
21582116      med2 remove_d  ecalfee  R        6:37      1 3   8G     c6-89
21581372   bigmemm samtools  ecalfee  R        6:37      1 4   32G    bigmem8

# TEST WITH a & b again. TEST UPDATED SNAKECODE






# testing snakemake pipeline
# make a very small dataset with 2 fastqs:
ecalfee@c6-93:~/hilo/data/HILO_raw_reads$ zcat April2020_1/HILO312_1.fq.gz | head -n 800 | gzip > TEST/a_1.fq.gz
ecalfee@c6-93:~/hilo/data/HILO_raw_reads$ zcat April2020_1/HILO312_2.fq.gz | head -n 800 | gzip > TEST/a_2.fq.gz
ecalfee@c6-93:~/hilo/data/HILO_raw_reads$ zcat April2020_1/HILO355_1.fq.gz | head -n 800 | gzip > TEST/b_1.fq.gz
ecalfee@c6-93:~/hilo/data/HILO_raw_reads$ zcat April2020_1/HILO355_2.fq.gz | head -n 800 | gzip > TEST/b_2.fq.gz
all_files = ["TEST/a.sort.dedup.baq.bam.bai", "TEST/b.sort.dedup.baq.bam.bai"]

# useful commands for conda environments:
# to list available environments
conda info -e
# to create conda environment (only do with -p 2022)
#conda create --name hilo-env --file environment.yaml
# to update conda environment: (only do when ssh'd into -p 2022)
#conda env update --name hilo-env --file envs/environment.yaml --prune
# to list packages and versions for hilo-env
#source activate hilo-env #activate
#conda list # list packages
#conda deactivate hilo-env # de-activate



# slurm nodes vs. tasks per node vs. cpus
# cores vs. nodes vs. tasks: https://docs.ycrc.yale.edu/clusters-at-yale/job-scheduling/resource-requests/
multi-process program = multiple tasks (--ntasks)
multi-threaded program = multiple cores, 1 task (--cpus-per-task)

e.g. running samtools sort with 8 threads:
https://hcc.unl.edu/docs/applications/app_specific/bioinformatics_tools/data_manipulation_tools/samtools/running_samtools_commands/
#SBATCH --nodes=1 -N
#SBATCH --ntasks-per-node=8  -n

# running bowtie2 with 16 threads.
#SBATCH --cpus-per-task=16 -c


# GREAT RESOURCE FOR SNAKEMAKE: http://garthkong.com/snakemake-resources/
# GREAT RESOURCE ON SNAKEMAKE FOR CLUSTER: https://www.sichong.site/2020/02/25/snakemake-and-slurm-how-to-manage-workflow-with-resource-constraint-on-hpc/
How to get an email for failed jobs: --mail-type {cluster.email_type} --mail-user {cluster.email}
# HOW TO USE DICTIONARIES TO MAP 1 SAMPLE TO MULTIPLE FILES: https://www.jakevc.com/posts/2019/07/snakemake-examples/
# HOW TO USE SUBWORKFLOWS: https://lachlandeer.github.io/snakemake-econ-r-tutorial/subworkflows-divide-and-conquer.html#subworkflow-basics
# DAVIS FARM USE OF SLURM AND PROFILES: http://bluegenes.github.io/posts/
# useful for later: merging files: (caution! this isn't docs for the most up-to-date snakemake)
"Here is an example where you want to merge N files together, but if N == 1 a symlink will do." https://snakemake.readthedocs.io/en/v3.9.1/project_info/faq.html


--shadow-prefix=/scratch/<username>
--use-conda
--number of submissions to slurm at a time etc.
shadow: "minimal"
# minimal only symlinks all the input files .. so make sure they are all the rule needs to access to run!

# TO-DO: get it to run, then make a .profile for basic slurm setup, check still runs
I made a profile for slurm: mkdir -p ~/.config/snakemake/slurm
nano ~/.config/snakemake/slurm/config.yaml
jobs: 100
cluster: sbatch
use-conda: true
# TO RUN WITH THIS PROFILE:
snakemake --profile slurm
# COOL -- ADD MORE MEMORY BASED ON ATTEMPT # https://snakemake.readthedocs.io/en/stable/snakefiles/rules.html

hmm...maybe resources can only take specific values (but seems not to be the case with high_mem_mb)

# then add additional quality check rules.
fast_QC
fastq_screen
samtools file information

# mark temporary output files
# then get your list of files 2 run. show DAG. start running.



snakemake -n # dry--run. could be along list!
snakemake -n --quiet # gives just a summary if there are LOTS of files
snakemake --dag **blah blah**

# don't want to see all the file paths, just the rules?
snakemake --rulegraph | dot -Tsvg > ruleGraph.svg


module load bio3
source activate hilo-env
snakemake results/TEST/b.bam --jobs 2 --cluster-config submit.json --cluster "sbatch -p {cluster.p} --mem {cluster.mem} --cpus-per-task {cluster.cpus-per-task} --time {cluster.time} --job-name {cluster.name} -e {cluster.e} -o {cluster.o}"

# ok in bash not main node
hilo$ srun --mem 8G -p med2 -t 2:00:00 --pty bash
source activate hilo-env
snakemake results/TEST/b.sort.bam --jobs 2 --cluster-config submit.json --cluster "sbatch -p {cluster.p} --mem {cluster.mem} --cpus-per-task {cluster.cpus-per-task} --time {cluster.time} --job-name {cluster.name} -e {cluster.e} -o {cluster.o}"


# create a snakemake copy of the environment.
ssh -p 2022 ecalfee@farm.cse.ucdavis.edu
module load conda3
source activate hilo-env
hilo$ snakemake -n all --use-conda --create-envs-only
Building DAG of jobs...
Conda environment ../envs/environment.yaml will be created.
hilo$ snakemake all --use-conda --create-envs-only



# anytime you update the conda environment:
ssh -p 2022 ecalfee@farm.cse.ucdavis.edu
cd hilo
hilo$ module load conda3
hilo$ conda env update --name hilo-env --file envs/environment.yaml --prune
hilo$ source activate hilo-env
hilo$ snakemake -n all --profile slurm --conda-create-envs-only
hilo$ snakemake all --profile slurm --conda-create-envs-only
#(use -n above if you just want to see which environments will be created)
hilo$ conda deactivate
hilo$ exit  # now log out of farm and re-log in without -p 2022 to run snakemake

# to run pipeline:
 start screen.
 screen -S snake
 snakemake all --profile slurm
[detached from 21715.snake] # hmm. things didn't run b/c low priority. also accidentally put screen on an sru nso lost it after I cancelled ind stalled jobs

# check after a bit if it ran through .. any errors?
# look at multiqc reports and library in bam file. samtools View bam
# then change TEST to your prefix. Commit DAG and simplified DAG.
# update GIT.
# Look at DAG. Look at simplified DAG. Then run all.
snakemake --dag all | dot -Tsvg > dag.svg
snakemake all --profile slurm
[detached from 32676.snake_run] # it's running in screen now


# argh, can't use this to parse wildcards in my 'profile', oh well: print(*{wildcards}.values(), sep = ".")





### ok so my original memory/time estimates were really high, possibly preventing my jobs from being scheduled efficiently. I added more dynamic memory with 3 total attempts for failed jobs and less intense status checking to reduce impact to farm (once every 2 sec)
### I cancelled original running snakemake process, but only had to cancel 1 individual job (let others scheduled run until complete).
### now running pipeline again:
ecalfee@farm:~/hilo$ screen -r 32676.snake_run
[detached from 32676.snake_run] 8.20.20 11pm
# two jobs got hung up (suspended). So I cancelled them. but snakemake doesn't seem to be rescheduling them.
ecalfee@farm:~$ squeue -u ecalfee
         JOBID PARTITION     NAME     USER ST        TIME  NODES CPU MIN_ME NODELIST(REASON)
      21613385   bigmemm bwa_map.  ecalfee  S     1:55:54      1 16  24G    bigmem3
      21612650   bigmemm bwa_map.  ecalfee  S     2:34:50      1 16  24G    bigmem3
ecalfee@farm:~$ screen -ls
There is a screen on:
	32676.snake_run	(05/19/2020 10:57:41 PM)	(Detached)
1 Socket in /run/screen/S-ecalfee.
ecalfee@farm:~$ scancel 21613385 21612650
ecalfee@farm:~$ screen -r 32676.snake_run
# HILO306 and HILO317 are the ones that got hung up and need to be rerun. I will also check what would need to be rerun if I included all the older files too.

# first make combined list with all samples except those affected by label errors:
(hilo-env) ecalfee@c6-97:~/hilo/data/HILO_raw_reads$ (cut -f1 merged_all.list; cat April2020_IDs.list) > Combined_IDs.list
(hilo-env) ecalfee@c6-97:~/hilo/data/HILO_raw_reads$ (cut -f3 merged_all.list; cat April2020_libraries.list) > Combined_libraries.list
~/hilo/data/HILO_raw_reads$ (cut -f2 merged_all.list; cat April2020_lanes.list) > Combined_lanes.list

# I had to rename the picard and fastQC reports to get snake to recognize samples were added: multiqc_report.html.backup
# I need to simlink the fastqs for March2018 and simlink (or just copy over) all of the mark duplicate metrics from previous runs to the correct directory.
snakemake -n --quiet all --profile slurm
# to keep directory naming consistent for snakemake to find files, I created symlinks for all March2018 fastqs into the March2018/ directory, not just March2018_all/
# only HILO71 was previously symlinked into this directory
(hilo-env) ecalfee@c6-97:~/hilo/data/HILO_raw_reads$ parallel 'ln -s $(ls /group/jrigrp6/DanAlignments/{1}/{1}_*_{2}.fq.gz) March2018/{1}_{2}.fq.gz' :::: March2018_all_IDs.list ::: 1 2
<<gnu parallel message>>
ln: failed to create symbolic link 'March2018/HILO71_1.fq.gz': File exists
ln: failed to create symbolic link 'March2018/HILO71_2.fq.gz': File exists
parallel 'ln -s $(ls /group/jrigrp6/DanAlignments/{1}/{1}_*_{2}.fq.gz) March2018/{1}_{2}.fq.gz' :::: March2018_all_IDs.list ::: 1 2

# updated time-stamp for symbolic links to show snakemake these files are current:
(hilo-env) hilo$ parallel 'ln -s $(ls /home/ecalfee/hilo/data/hilo_bam_mapped2v4_allContigs/metrics/hilo_{1}.metrics.txt) filtered_bams/metrics/picard/March2018/HILO{1}.metrics.txt' ::: {1..70} {72..79} {81..200}
hilo$ parallel 'unlink filtered_bams/results/March2018/HILO{1}.sort.dedup.baq.bam; ln -s /home/ecalfee/hilo/data/hilo_bam_mapped2v4_allContigs/results/hilo_{1}.sort.dedup.baq.bam filtered_bams/results/March2018/HILO{1}.sort.dedup.baq.bam; ' ::: {1..70} {72..79} {81..200}
hilo$ parallel 'unlink filtered_bams/results/March2018/HILO{1}.sort.dedup.baq.bam.bai; ln -s /home/ecalfee/hilo/data/hilo_bam_mapped2v4_allContigs/results/hilo_{1}.sort.dedup.baq.bam.bai filtered_bams/results/March2018/HILO{1}.sort.dedup.baq.bam.bai; ' ::: {1..70} {72..79} {81..200}

# good! now snakemake doesn't want to remake these files anymore :)
(hilo-env) ecalfee@c6-97:~/hilo$ snakemake -n --quiet all --profile slurm
Job counts:
	count	jobs
	1	all
	2	bwa_map
	1004	fastQC
	1	multiQC_fastQC
	1	multiQC_flagstat
	1	multiQC_picard
	2	remove_duplicates
	315	samtools_flagstat
	2	samtools_index
	2	samtools_sort
	1331
# now I will stop and restart snakemake on my screen instance:
snakemake all --profile slurm
# running: [detached from 32676.snake_run]
# all ran fine except HILO1 b/c fastq_1 for that file appears to have been truncated!
hilo$ less filtered_bams/snake_logs/fastQC.ID\=HILO1\,LANE\=March2018\,READ\=1.21816*err
...
Approx 95% complete for HILO1_1.fq.gz
Failed to process file HILO1_1.fq.gz
uk.ac.babraham.FastQC.Sequence.SequenceFormatException: Ran out of data in the middle of a fastq entry.  Your file is probably truncated
ecalfee@c6-97:~/hilo$ zcat data/HILO_raw_reads/March2018/HILO1_1.fq.gz | wc -l
gzip: data/HILO_raw_reads/March2018/HILO1_1.fq.gz: unexpected end of file
24590717
(hilo-env) ecalfee@c6-97:~/hilo$ zcat data/HILO_raw_reads/March2018/HILO1_2.fq.gz | wc -l
33132348
# When iplant is back online I can check if we have a backup. Looks like truncation likely happened after mapping/deduplication etc. so all the reads may be there somewhere.
# for now I will just do a 'touch' placeholder for that fastQC file so I can finish snakemake.
hilo$ touch filtered_bams/metrics/fastQC/March2018/HILO1_1_fastqc.html
hilo$ snakemake -n --quiet all --profile slurm
Job counts:
	count	jobs
	1	all
	1	multiQC_fastQC
	2
snakemake all --profile slurm
# ran out of time. Increased max time to 2hrs. Will rerun when I fix the dedup step also here:
# in my original MarkDuplicates I didn't actually remove duplicates. I add a rule rm_duplicates using samtools flag 0x0400
# then to use that rule I rename my prior output HILO*.sort.mrkdup.baq.bam.
# note this only applies to the April2020 data. previous data had duplicates removed during MarkDuplicates (can see in flagstat):
hilo/filtered_bams/results/April2020_1$ for i in {300..395}; do mv HILO$i.sort.dedup.baq.bam HILO$i.sort.mrkdup.baq.bam; done
hilo/filtered_bams/results/April2020_1$ for i in {300..395}; do touch HILO$i.sort.mrkdup.baq.bam; done
hilo/filtered_bams/results/April2020_2$ for i in {396..488}; do mv HILO$i.sort.dedup.baq.bam HILO$i.sort.mrkdup.baq.bam; done
hilo/filtered_bams/results/April2020_2$ for i in {396..488}; do touch HILO$i.sort.mrkdup.baq.bam; done
# now running snakemake all for 'Combined' samples again on screen:
snakemake all -n --quiet --profile slurm
Job counts:
	count	jobs
	1	all
	1	multiQC_fastQC
	1	multiQC_flagstat
	189	rm_duplicates
	189	samtools_flagstat
	189	samtools_index
	570

# following up on truncated HILO1 -- Dan replaced with original file from /group/jrigrp6/DanAlignments/HILO1/*_1.fq.gz. I should now re-do mapping for HILO1.
# checking checksums for all other files that the ones I used from DanAlignments are identical to the originals
ecalfee@bigmem3:~/hilo$ for i in {1..200}; do md5sum /group/jrigrp6/DanAlignments/HILO"$i"/*.fq.gz > data/HILO_raw_reads/MD5_checksums/March2018/HILO"$i"_MD5.txt; done
# ugh..I just put this into a short script to submit to sbatch instead:
hilo$ sbatch scripts/check_md5sums.sh
Submitted batch job 21891631
# original checksums are here: /group/jrigrp6/RILAB_data/HILO/raw_data/HILO1/MD5.txt
# now I can do a file difference check: (except I only want to check the 1st column)
hilo$ for i in {1..79} {81..200}; do diff <(cut -f1 /group/jrigrp6/RILAB_data/HILO/raw_data/HILO"$i"/MD5.txt -d" ") <(cut -f1 data/HILO_raw_reads/MD5_checksums/March2018/HILO"$i"_MD5.txt -d" "); done
# great! just HILO1 had a truncated file. I will remap HILO1 which snakemake detected automatically because the fastq_1 was updated by Dan:
# I need to update my iplant backup using irsync - COMPLETED.
I also fixed samtools_flagstat rule to read the bam properly with - in the pipe, so all 190 of those are also running too for April2020 sequences.
Job counts:
	count	jobs
	1	all
	1	bwa_map
	2	fastQC
	1	mark_duplicates
	1	multiQC_fastQC
	1	multiQC_flagstat
	1	multiQC_picard
	1	rm_duplicates
	190	samtools_flagstat
	1	samtools_index
	1	samtools_sort
	201
[detached from 32676.snake_run]  5.26.20 9pm
# annoyingly TIMEOUT (CANCELLED) wasn't caught by slurm as a job failure, so it didn't try again. I will up time manually and run again:
# e.g. output files:
'filtered_bams/snake_logs/samtools_flagstat.ID=HILO428,LANE=April2020_2.21898239.err'
'filtered_bams/snake_logs/samtools_flagstat.ID=HILO428,LANE=April2020_2.21898239.out'
# so I added threads and 2 hours (now 6 hrs total) for initial samtools flagstat run -- HILO301, HILO305, HILO428:
[detached from 32676.snake_run] #May 27, 9:30am. Finished super fast (not sure what caused TIMEOUT earlier)
# rerun multiqc ignoring test bams:
hilo$ snakemake multiQC_picard multiQC_flagstat multiQC_fastQC -f -n --quiet --profile slurm
Job counts:
	count	jobs
	1	multiQC_fastQC
	1	multiQC_flagstat
	1	multiQC_picard
	3
(hilo-env) ecalfee@c6-97:~/hilo$ snakemake multiQC_picard multiQC_flagstat multiQC_fastQC -f --profile slurm

# testing trimmomatic:
hilo$ snakemake -f /home/ecalfee/hilo/data/HILO_trimmed_reads/TEST/a_1.fq.gz --profile slurm
# added TRUE . now seeing if it successfully removes adapters from the small test sets of reads:
snakemake metrics/fastQC_trimmed/multiqc/multiqc_report.html --profile slurm
# looks good on fastQC report!

# I made an alternative 'some' rule to the 'all' rule to just make trimmed_reads multiQC report and do bwa -> sorting reads. ack! in testing it removes temporary output file. So I get rid of the temp for now.
# first tested with just TEST/a.fq and b.fq. Now running with Combined sample:
hilo$ snakemake -n some --quiet --profile slurm
Job counts:
        count   jobs
        502     bwa_map
        1004    fastQC_trimmed
        1       multiQC_fastQC_trimmed
        502     samtools_sort
        1       some
        502     trimmomatic
        2512
snakemake some --profile slurm
[detached from 32676.snake_run] # May 28, 2020 11:39pm

# I will have to decide later whether I want to cap base quality scores with BAQ, so I don't dedup yet in this run:
hilo$ snakemake -n some --quiet --profile slurm
Job counts:
	count	jobs
	1	all
	502	bwa_map
	1004	fastQC_trimmed
	1	multiQC_fastQC_trimmed
	502	samtools_sort
	502	trimmomatic
	2512

# snakemake seemed frozen from log on Jun 4, so I did CTRL+C:
Terminating processes on user request, this might take some time.
Will exit after finishing currently running jobs.
Complete log: /home/ecalfee/hilo/.snakemake/log/2020-05-28T233738.667066.snakemake.log
hilo$ snakemake -n some --quiet --profile slurm
Job counts:
        count   jobs
        1       bwa_map
        4       fastQC_trimmed
        1       multiQC_fastQC_trimmed
        1       samtools_sort
        1       some
        1       trimmomatic
        9
# REMINDER, HOW TO USE SCREEN: https://linuxize.com/post/how-to-use-linux-screen/
# ok, restarting these failed jobs (can't determined why they failed from logs, so could be random)
hilo$ snakemake some --profile slurm # RUNNING 6.25.2020
CRTL+A D
[detached from 32676.snake_run]


TEST ANGSD MIXING BAMS FROM GENOMES WITH DIFF SORT ORDERS:
# take 10 maize from hilo
# and 10 maize from Palmar Chico maize pop

# are the number of SNPs reasonable? Are they all at 50% freq?
hilo/test$ angsd -out test_10JRI_10alloMAIZE -r 1:100000000-100010000 -ref ../data/refMaize/Zea_mays.B73_RefGen_v4.dna.toplevel.fa -bam maize_10JRI_10alloMAIZE.bams -remove_bads 1 -minMapQ 30 -minQ 20 -doCounts 1 -minMaf 0.05 -doMaf 8 -GL 1 -doGlf 2 -P 1 -doMajorMinor 2 -checkBamHeaders 0
hilo/test$ samtools view -bs 42.001 /home/jri/projects/ibd/JRIAL1/data/JRIAL1-2_srt_dedup.bam > small_JRIAL1-2_srt_dedup.bam
# index this bam
# try to run test2.bams -- has small_JRIAL1-2_srt_dedup.bam and some hilo's
hilo/test$ angsd -out test2 -r 2:100000000-110000000 -ref ../data/refMaize/Zea_mays.B73_RefGen_v4.dna.toplevel.fa -bam test2.bams -remove_bads 1 -minMapQ 30 -minQ 20 -doCounts 1 -minMaf 0.05 -doMaf 8 -GL 1 -doGlf 2 -P 1 -doMajorMinor 2 -checkBamHeaders 0
# again but without this 1 bam from palmar chico = test2b:
angsd -out test2b -r 2:100000000-110000000 -ref ../data/refMaize/Zea_mays.B73_RefGen_v4.dna.toplevel.fa -bam test2b.bams -remove_bads 1 -minMapQ 30 -minQ 20 -doCounts 1 -minMaf 0.05 -doMaf 8 -GL 1 -doGlf 2 -P 1 -doMajorMinor 2 -checkBamHeaders 0

# then re-sort according to the my genome
hilo/test$ samtools sort -m 6G -@ 1 -T tmp -O bam small_JRIAL1-2_srt_dedup.bam > small_JRIAL1-2_srt_dedup.resorted.bam
# and try to run test3 -- has small_JRIAL1-2_srt_dedup.resorted.bam and some hilo's
# the resulting SNP files should be the same from these two approaches if it's working
hilo/test$ angsd -out test3 -r 2:100000000-110000000 -ref ../data/refMaize/Zea_mays.B73_RefGen_v4.dna.toplevel.fa -bam test3.bams -remove_bads 1 -minMapQ 30 -minQ 20 -doCounts 1 -minMaf 0.05 -doMaf 8 -GL 1 -doGlf 2 -P 1 -doMajorMinor 2 -checkBamHeaders 1

# hmm...still headers don't match. Try picard ReorderSam:
module load java
module load picardtools/2.7.1
java -Xmx6g -jar $PICARD/picard.jar ReorderSam \
INPUT= small_JRIAL1-2_srt_dedup.bam OUTPUT=small_JRIAL1-2_srt_dedup.reordered.bam \
REFERENCE=../data/refMaize/Zea_mays.B73_RefGen_v4.dna.toplevel.fa
test4.bams has the reordered bam file:
samtools index small_JRIAL1-2_srt_dedup.reordered.bam
hilo/test$ angsd -out test4 -r 2:100000000-110000000 -ref ../data/refMaize/Zea_mays.B73_RefGen_v4.dna.toplevel.fa -bam test4.bams -remove_bads 1 -minMapQ 30 -minQ 20 -doCounts 1 -minMaf 0.05 -doMaf 8 -GL 1 -doGlf 2 -P 1 -doMajorMinor 2
# runs just fine without checking bam headers ..
# maize palmar chico needs to run ReorderSam (above) + dedup marked dups + filter to mapQ>=1
hilo/test$ samtools view -bF 0x400 -q 1 small_JRIAL1-2_srt_dedup.bam | samtools flagstat -
# ok actually I don't want to copy these all over (> 2T). As long as I just use autosomes, the order is the same in bams, so angsd should work with -checkBamHeaders flag
# BUT I do need to make sure to use the -removeBads 1 and -mapQ 30 and -baq 2 in ANGSD because these files
# have no pre-computed baq and only actually mark (not remove) duplicate reads

# make symlinks for all maize 55 data to the filtered bams folders
hilo/filtered_bams/results/Maize55$ for i in {1..55}; do ln -s /home/jri/projects/ibd/JRIAL1/data/JRIAL1-"$i"_srt_dedup.bam MAIZ"$i".sort.dedup.bam; done

# rerun snakemake to dedup all hilo and then index everything, incl. maize 55
# note that maize55 I got pre-mapped (w/ bwa) and duplicates marked, but all reads included (even unmapped)
screen -r 32676.snake_run
(IN SCREEN:)
Job counts:
	count	jobs
	1	all
	502	mark_duplicates
	1	multiQC_flagstat
	557	samtools_flagstat
	557	samtools_index
	1618
hilo$ snakemake all --profile slurm
CTRL+A+D (detached screen. June 26, 2020 11:55pm)
# ran fine. Now I merge bams for the same individual. Syntax here in snakemake is a bit tricky. shell only (not run) is required to use conda
snakemake all -n --profile slurm
# running test case with a/b files 6.30.2020. Oops next time don't test with multiQC reports (will inclue a & b test files in there too)
screen -r 32676.snake_run
[detached from 32676.snake_run]
# oops. merge bams not just for the sample cases:
(hilo-env) ecalfee@farm:~/hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        520     merge_bams
        521
(hilo-env) ecalfee@farm:~/hilo$ snakemake all --profile slurm # running 7.7.2020

# calculating depth for minQ > 20:
(hilo-env) ecalfee@farm:~/hilo$ snakemake -n calc_depth --profile slurm
Building DAG of jobs...
Job counts:
        count   jobs
        1       calc_depth
        1

[Tue Jul  7 01:46:57 2020]
rule calc_depth:
    input: ../samples/HILO_MAIZE55_bams.list, /home/ecalfee/hilo/data/refMaize/random_regions/N1000.L100.regions
    output: results/depthCov/N1000.L100.regions/HILO_MAIZE55.Q20.depthGlobal
    jobid: 0
    threads: 4
    resources: time_min=720, mem=32
# make output directory for logs!
mkdir variant_sites/snake_logs
# now run:
hilo$ snakemake calc_depth --profile slurm # didn't work. Now I've fixed the working directory issue (always just points to hilo/ for variant_sites Snakemake)
hilo$ snakemake calc_depth --profile slurm # 7.7.2020 RUNNING: Submitted job 0 with external jobid '24113628'
# now calling SNPs using a max depth cutoff that's read in from the output of the calc_depth rule
(hilo-env) ecalfee@farm:~/hilo$ snakemake -n --quiet all --profile slurm
Job counts:
        count   jobs
        1       all
        426     call_SNPs
        427
# running 7.7.2020 6pm . oops typo didn't work. trying again:
snakemake -n --quiet all  --profile slurm
Job counts:
        count   jobs
        1       all
        426     call_SNPs
        426     make_sites_file
        853

# most but not all call_SNPs completed. none of the make_sites_file rule was successful.
(hilo-env) ecalfee@farm:~/hilo$ snakemake -n --quiet all --profile slurm
Job counts:
        count   jobs
        1       all
        426     calc_rmap_pos
        116     call_SNPs
        426     make_sites_file
        969
# testing 1 file:
hilo$ snakemake variant_sites/results/HILO_MAIZE55/region_1.rpos --profile slurm
Job counts:
        count   jobs
        1       calc_rmap_pos
        1       make_sites_file
        2
# worked great. Doing 2 more files so I can also test my regions script:
hilo$ snakemake variant_sites/results/HILO_MAIZE55/region_0.rpos variant_sites/results/HILO_MAIZE55/region_300.rpos --profile slurm
# testing regions script with just 0, 1, 300 regions for now (need to change back in global_ancestry/Snakefile!!)
snakemake -n --quiet some --profile slurm
Job counts:
        count   jobs
        1       some
        1       thin_GL_4PCA
        2
No rule to produce variant_sites/results/HILO_MAIZE55/region_3.mafs.gz (if you use input functions make sure that they don't raise unexpected exceptions).
# ok thin_GL_4PCA still has issues (troubleshoot on mac). but re-running the failed jobs from call_SNPs for now:
hilo$ snakemake -n --quiet all --profile slurm --jobs 200
Job counts:
        count   jobs
        1       all
        423     calc_rmap_pos
        116     call_SNPs
        423     make_sites_file
        963
(hilo-env) ecalfee@farm:~/hilo$ snakemake all --profile slurm --jobs 200 # running 7.8.2020 all on medium priority but increased max to 200 jobs
[detached from 32676.snake_run] # ack! not sure what the deal is with farm but I won't use --jobs to override again (maybe overrides all defaults too?? like pinging the server? or could be completely unrelated)
# testing locally with a subset of regions. Need to specify --use-conda to run in updated conda environment
 Erins-MacBook-Air:hilo Erin$ snakemake test --use-conda
# can't update my conda environment on mac because of linux-ony pcangsd install :( but it runs on farm so ok

# rerunning several files because 'regions_dict' wasn't found (I think it doesn't freeze the Snakefile even when running..)
hilo$ snakemake -n --quiet all --profile slurm
Job counts:
        count   jobs
        1       all
        392     calc_rmap_pos
        1       call_SNPs
        339     make_sites_file
        1       run_NGSAdmix
        1       run_PCAngsd
        1       thin_GL_4PCA
        736
hilo$ snakemake all --profile slurm # running 7.8.2020
[detached from 32676.snake_run]

TO DO: make snakemake rules for all of the pcangsd and ngsadmix plots that you want
# NGSAdmix proportion by elevation, a PCA plot. I'll need metadata for the new maize.
# You can use the very short combined GL file as a template.

# made a file with half of the regions:
ecalfee@c6-89:~/hilo$ awk -v N=2 '(NR + 1) % N == 0' data/refMaize/divide_5Mb/ALL_regions.list > data/refMaize/divide_5Mb/HALF_regions.list
ecalfee@c6-89:~/hilo$ grep 'region_361' data/refMaize/divide_5Mb/HALF_regions.list # problem region that hasn't finished isn't included
ecalfee@c6-89:~/hilo$ head data/refMaize/divide_5Mb/HALF_regions.list
# just picked a small set of regions for a test file (downloading now from farm to laptop):
hilo Erin$ for i in 0 1 50 51 100 101 150 151 200 201 250 251 300 301 350 351 400 401; do scp -P 2022 ecalfee@farm.cse.ucdavis.edu:~/hilo/variant_sites/results/HILO_MAIZE55/region_$i.beagle.gz variant_sites/results/HILO_MAIZE55/.; done
# running test on mac for just these few regions:
(hilo-env) Erins-MacBook-Air:hilo Erin$ snakemake test
Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Unlimited resources: mem, time_min
Job counts:
	count	jobs
	1	test
	1	test_NGSAdmix
	1	test_thin_GL_4PCA
	3

# got script to run to make lists of input files by population,
# but still can't get plotting script to work for just counts (not sure why -- will check)
# now running test of getting allopatric allele frequencies (to thin sites for local ancestry)
hilo$ snakemake -n some --quiet --profile slurm
Job counts:
        count   jobs
        1       allo_freqs
        1       list_total_samples
        1       some
        3
# ok now that I fixed angsd indexing (needs .bin file too) the example in 'some' did run.
# will try running all of the regions to get MAF for allopatric references
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        851     allo_freqs
        424     index_sites_file
        1       plot_total_samples
        1277
# now running 'all'
[detached from 32676.snake_run] # Jul 19, 11:33pm
# looks like all allopatric mexicana ran overnight but there was a problem with bam file lists for allopatic maize. fixing now:
hilo$ snakemake -f list_total_samples --profile slurm
1 of 1 steps (100%) done
# now using 'touch' to avoid re-doing all allopatric mexicana (just want to re-do maize)
# and fixed small typo in plot_total_samples_pass.R (should work now)
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        426     allo_freqs
        1       plot_total_samples
        428
        # RUNNING 7.20.20 11:37am
# oops still not finding correct MAIZE55 bams. Fixed list of bams. re-did list_total_samples and 'touch' for allopatric mexicana mafs.gz files.
hilo$ snakemake -n all --quiet --profile slurm
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        426     allo_freqs
        1       plot_total_samples
        428 # RUNNING 7.20.20 12:30pm
# these jobs finished. adding PCA plots and running rule 'all' again:
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        1       plot_NGSAdmix
        1       plot_PCAngsd
        1       plot_total_samples
        1       results_NGSAdmix
        5 # runnning 7.20.20 9pm
# SWITCHED to thinning every 100th SNP for PCA/NGSAdmix instead of every .01cM (so I don't get over-representation of high recombination regions)
# moved old results to Old_0.1cM subdirectories for thinnedSNPs, PCA and NGSAdmix. Updated Snakefile to rerun.
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        1       plot_NGSAdmix
        1       plot_PCAngsd
        1       results_NGSAdmix
        1       run_NGSAdmix
        1       run_PCAngsd
        1       thin_GL_4PCA
        7 # running 7.21.20 6:25pm
# every Nth is not working in Snakefile. made it's own script and rerunnig:
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        1       plot_NGSAdmix
        1       plot_PCAngsd
        1       results_NGSAdmix
        1       run_NGSAdmix
        1       run_PCAngsd
        1       thin_GL_4PCA
        7 # running 7.21.20 12:36am
# rerunning with slight adjustments to plots:
hilo$ snakemake -n plot_PCAngsd plot_NGSAdmix --quiet --profile slurm
Job counts:
        count   jobs
        1       plot_NGSAdmix
        1       plot_PCAngsd
        2 # 7.22.20 10:15am
# added latex table output (updated conda environment for r-xtable) and re-running again:
hilo$ snakemake -n -f plot_PCAngsd plot_NGSAdmix --quiet --profile slurm
Job counts:
        count   jobs
        1       plot_NGSAdmix
        1       plot_PCAngsd
        2 # running 7.22.20 11:20am

# HMMM... the cubic spline "hyman" extrapolates out to some negative recombination map distances (!).
# I am calculating rpos based on linear approximation from the extended map, and saving old files in ls variant_sites/results/HILO_MAIZE55/splines_old/
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        426     calc_rmap_pos
        427 # running 8.3.2020 10pm. COMPLETED.

# made pipeline to do 100 bootstraps of global ancestry ~ recombination quintile (1cM window)
snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        1       define_1cM_windows
        1520    find_SNPs_in_window
        1       make_bed_file_for_windows
        505     make_bootstrap_GL_file
        1       sample_bootstrap_1cM
        2029 # running 8.4.2020 5pm. Did not work b/c it's circular to read file to get the number of 1cM windows -- have to provide that separately
        hilo$ snakemake -n all --quiet --profile slurm

Job counts:
        count   jobs
        1       all
        1       define_1cM_windows
        1520    find_SNPs_in_window
        505     label_k_anc
        1       make_bed_file_for_windows
        505     make_bootstrap_GL_file
        505     run_boostrap_NGSAdmix
        1       sample_bootstrap_1cM
        3039 # running 8.4.2020 11pm
# oops forgot double brackets in R scripts to call snakemake variables. fixed and re-trying.
# awk to find SNPs in windows still not working. added it's own bash script for awk and testing just this piece:
hilo$ snakemake ancestry_by_r/results/GL_1cM/HILO_MAIZE55/W1.beagle.gz --quiet --profile slurm
Job counts:
        count   jobs
        1       find_SNPs_in_window
        1 # finally ran through without errors. Now running all pieces:
        hilo$ snakemake all --quiet --profile slurm
        Job counts:
                count   jobs
                1       all
                1519    find_SNPs_in_window
                505     label_k_anc
                505     make_bootstrap_GL_file
                505     run_boostrap_NGSAdmix
                1       sample_bootstrap_1cM
                3036 # running 8.5.2020 10am. only ran through find_SNPs_in_window
hilo$ snakemake all --quiet --profile slurm
Job counts:
      count   jobs
      1       all
      505     label_k_anc
      505     make_bootstrap_GL_file
      505     run_boostrap_NGSAdmix
      1       sample_bootstrap_1cM
      1517 # fixed typo in path of sample_bootstrap_1cM. rerunning.

# ok problem is that the bin_r5 is not a factor with defined levels.
# so I added a column quintile_r5 that has values 1-5.
# I will force rerun define_1cM_windows and make_bed_file_for_windows
# and use touch to not have to redo find_SNPs_in_window, which would be unaffected
hilo$ snakemake -f define_1cM_windows make_bed_file_for_windows --quiet --profile slurm
Job counts:
        count   jobs
        1       define_1cM_windows
        1       make_bed_file_for_windows
        2 # COMPLETED 8.5.2020
hilo$ touch ancestry_by_r/results/GL_1cM/HILO_MAIZE55/W*.beagle.gz
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        505     label_k_anc
        505     make_bootstrap_GL_file
        505     run_boostrap_NGSAdmix
        1       sample_bootstrap_1cM
        1517 # RUNNING 8.5.2020

# NOTE: don't use any kind of shadow when running a bash script through 'shell' (or put script in as a parameter..)
# In general I don't need 'shadow' unless there's lots of reading and writing.
hilo$ snakemake -n all --quiet --profile slurm                                    Job counts:
        count   jobs
        1       all
        505     label_k_anc
        504     make_bootstrap_GL_file
        505     run_boostrap_NGSAdmix
        1515 # RUNNING 8.5.2020 6pm. hmm didn't work. debugged make_bootstrap_GL_file, label_k_anc and run_bootstrap_NGSAdmix one at a time with 1 file each

hilo$ snakemake all --quiet --profile slurm
Job counts:
      count   jobs
      1       all
      504     label_k_anc
      504     run_bootstrap_NGSAdmix
      1009 # running 8.6.2020 11am. Ran through:
# now making plots (remaking some others because I updated colors.R)
Job counts:
        count   jobs
        1       all
        1       plot_NGSAdmix
        1       plot_PCAngsd
        1       plot_bootstrap_anc_by_r
        4 # RUNNING 8.6.2020 4pm. COMPLETED ALL PLOTS
# rerunning population alphas output from ngsadmix to use as input for ancestry_hmm (admixture proportion prior)
hilo$ snakemake -f global_ancestry/results/NGSAdmix/HILO_MAIZE55/K2_alphas_by_symp_pop.txt --quiet --profile slurm
Job counts:
        count   jobs
        1       results_NGSAdmix
        1 # RUNNING 8.6.2020 5pm
hilo$ snakemake -n all --quiet --profile slurm
      Job counts:
      count   jobs
      1       all
      1       plot_NGSAdmix
      1       thin_AIMs
      3
# ERROR in thin_sites_4HMM. problem was NAs in rpos files. remaking those files:
hilo$ snakemake -n all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        426     calc_rmap_pos
        1       thin_sites_4HMM
        428 # RUNNING 8.11.2020. Again didn't work. Fixed reading in columns of extended map, deleted rpos files with lots of NAs and rerunning.
# thin sites ran. trying one file to test counts pipeline:
hilo$ snakemake local_ancestry/results/countsMajMin/HILO_MAIZE55/HILO2.counts.txt --quiet --profile slurm
Job counts:
        count   jobs
        1       count_ACGT
        1       count_maj_min
        1       index_sites_4HMM
        3 # made index of sites ok and started on ACGT counts but then I stopped the job I could run all of the samples:
hilo$ snakemake -n some --quiet --profile slurm
Job counts:
        count   jobs
        403     count_ACGT
        403     count_maj_min
        1       some
        807 # RUNNING 8.11.2020
# note the above is slightly inefficient because I have it make a counts file for all included samples (all_ids) when some sympatric samples will be excluded for coverage < 0.5x
# but rather than have dynamic inputs for each population, I can use all of these counts files as inputs for each of the following rules to make the pop input files.
farm:~/hilo$ snakemake some --quiet --profile slurm
Job counts:
        count   jobs
        49      count_ACGT
        49      count_maj_min
        1       some
        99 # some need to be rerun with higher maximum time limit (I added a thread and changed from 4 to 12 hrs because MAIZE55 bams are very large). Unfortunately, the "TIMEOUT" didn't trigger a "FAIL" and rerun.
# RUNNING 8.12.2020 9:30am


### HMM... so I want the lists of bams/IDs to be outside of my Snakemake pipeline
# so that I can use them as inputs.
# I can force rerun: rule list_total_samples in filtered_bams/Snakefile
# then use 'touch' to update downstream files (because it will be the same outputs, because results/Maize55/*.bam is symlinked to results/merged_bams/*.bam)
# then I can comment out that code and use the output files to fill a dictionary of IDs for each population
hilo$ snakemake -f list_total_samples --quiet --profile slurm
Job counts:
        count   jobs
        1       list_total_samples
        1 # RUNNING 8.13.2020 11:45am
This fixes ALLOPATRIC MAIZE LOOKS LIKE IT COMES FROM A DIFFERENT DIRECTORY IN THE ALL_byPop files! (but not Over0.5x_byPop files). this is just a symlink issue, both link to the same underlying files. But I should fix so the symlink name pattern is consistent across all bams.
# there are many downstream files that depend on list_total_samples:
        hilo$ snakemake -n all --quiet --profile slurm
        Job counts:
                count   jobs
                1       all
                852     allo_freqs
                403     count_ACGT
                403     count_maj_min
                1       index_sites_4HMM
                1       plot_total_samples
                1       thin_sites_4HMM
                1662
# touch so I don't have to remake downstream files (because will be the same since inputs changed only by name (symlink) not content)
hilo$ touch variant_sites/results/popFreq/allopatric_*/*
hilo$ touch local_ancestry/results/thinnedSNPs/HILO_MAIZE55/whole_genome.var.sites
hilo$ touch local_ancestry/results/thinnedSNPs/HILO_MAIZE55/whole_genome.*
hilo$ touch local_ancestry/results/thinnedSNPs/HILO_MAIZE55/counts_thinned_aims.txt
hilo$ touch samples/HILO_MAIZE55_byInd/*_bams.list
hilo$ touch local_ancestry/results/countsACGT/HILO_MAIZE55/*
hilo$ touch local_ancestry/results/countsMajMin/HILO_MAIZE55/*
hilo$ snakemake all --quiet --profile slurm
Job counts:
        count   jobs
        1       all
        1       plot_total_samples
        2 # DONE
# commented out list_total_samples rule and added all sample files to git!

# making input files for ancestry_hmm:


# NOTE: I should delete intermediate files from 'all' because it possibly slows down creating DAG (e.g. if they've already been used already it wouldn't need to check them?)
# TO DO:
# RUNNING (0) Do I need to calc other allele freqs before choosing SNPs for local ancestry?
      - yes, working on allopatric allele frequencies now
      # (0.5) Why doesn't the counts plot work??

# DONE (3) Get included individuals to run local ancestry inference
        # Done. I made these byPop files.
# (4) Filter SNPs for local ancestry inference (1 chromosome at a time? 1 region?)
# (5) Set up to run all pops local ancestry inference

# (For supplement: Add parviglumis & re-call SNPs & do PCAngsd and NGSAdmix with 3 ancestries)
